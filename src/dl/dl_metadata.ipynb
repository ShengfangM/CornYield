{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Specify the new directory path\n",
    "parent_directory = 'D:/Projects/CornYield/src'\n",
    "\n",
    "# Change the current directory\n",
    "os.chdir(parent_directory) \n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_filename_metadata\n",
    "from dl.dl_dataset import MixedDataset\n",
    "from dl.train import train_with_cross_validation, train, validate, data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.model import ResNetRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_var={\n",
    "    3: 'all',\n",
    "    2: 'P9998',\n",
    "    1: 'CH 192-10',\n",
    "    0: 'DKC 51-91'\n",
    "}\n",
    "\n",
    "irrigate_var={\n",
    "    2: 'All',\n",
    "    0: 'Full',\n",
    "    1: 'Deficit'\n",
    "}\n",
    "yield_file = 'D:/Corn_Yield/BL2022_Yld_label.csv'\n",
    "weather_file = 'D:/Corn_Yield/CoAgMet ET_VBA_calc_2022.xlsm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list=[\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220616_DOY167_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220628_DOY179_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220708_DOY189_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "]\n",
    "doy_list=[167, 179, 189, 201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220616_DOY167_extracted_filled'\n",
    "# out_path = '../output/DOY167/'\n",
    "# doy = 167\n",
    "img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220705_DOY186_extracted_filled'\n",
    "out_path = '../output/DOY186/'\n",
    "doy = 186\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "# out_path = '../output/DOY201/'\n",
    "# doy=201\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220708_DOY189_extracted_filled'\n",
    "# out_path = '../output/DOY189/'\n",
    "# doy=189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220628_DOY179_extracted_filled'\n",
    "# out_path = '../output/DOY179/'\n",
    "# doy = 179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220716_DOY197_extracted_filled'\n",
    "# out_path = '../output/DOY197/'\n",
    "# doy = 197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(yield_pf, weather_file, doy):\n",
    "\n",
    "    weather_pf = pd.read_excel(weather_file,sheet_name=1, header=[0,1,3])\n",
    "    # header_name = weather_pf.columns\n",
    "    # selected_rows = weather_pf[(weather_pf[header_name[-1]] > doy-6) & (weather_pf[header_name[-1]] < doy+6)]\n",
    "    weather_pf = pd.read_excel(weather_file,sheet_name=1, header=[0,1,3])\n",
    "    weather_pf = weather_pf.dropna()\n",
    "\n",
    "    selected_rows = weather_pf[(weather_pf.iloc[:,-1] > doy-6) & (weather_pf.iloc[:,-1]  < doy+6) ]\n",
    "\n",
    "    air_temperature = selected_rows.iloc[:,2].mean()\n",
    "    precipitation = selected_rows.iloc[:,9].mean()\n",
    "    soil_temperature = selected_rows.iloc[:,10].mean()\n",
    "    soil_temperature2 = selected_rows.iloc[:,11].mean()\n",
    "\n",
    "    metadata = pd.DataFrame(index=range(len(yield_pf)))\n",
    "    metadata['Variety'] = yield_pf['Variety_int']/2\n",
    "    metadata['Irrigation'] = yield_pf['Irrigation_int']/1\n",
    "    metadata['DOY'] = doy / 366\n",
    "    metadata['Month'] = (doy / 30)/12\n",
    "    metadata['Stage'] = (doy/30 - 5)/5\n",
    "    metadata['air_temperature'] = air_temperature\n",
    "    metadata['precipitation'] = precipitation\n",
    "    metadata['soil_temperature'] = soil_temperature\n",
    "    metadata['soil_temperature2'] = soil_temperature2\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CROP_Variety = {\n",
    "    'P9998': 2,\n",
    "    'CH 192-10':1,\n",
    "    'DKC 51-91':0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_data(img_path_list, yield_file,keyword,doy_list, analyze_variety_id, analyze_irrigation_id:int=2):\n",
    "    all_img_list = []\n",
    "    all_yield_list = []\n",
    "    meta_df = pd.DataFrame()\n",
    "    # all_train_indices = []\n",
    "    yield_pf_all = pd.DataFrame()\n",
    "    for (img_path,doy) in zip(img_path_list,doy_list):\n",
    "        print(doy)\n",
    "        img_list, yield_pf = get_filename_metadata(img_path, yield_file, keyword)\n",
    "\n",
    "        if analyze_variety_id != 3 or analyze_irrigation_id != 2:\n",
    "            if analyze_variety_id != 3 and analyze_irrigation_id != 2:\n",
    "                yield_pf = yield_pf[(yield_pf['Variety_int'] == analyze_variety_id) & (yield_pf['Irrigation_int'] == analyze_irrigation_id)]\n",
    "            elif analyze_variety_id != 3:\n",
    "                yield_pf = yield_pf[yield_pf['Variety_int'] == analyze_variety_id]\n",
    "            elif  analyze_irrigation_id != 2:\n",
    "                yield_pf = yield_pf[ yield_pf['Irrigation_int'] == analyze_irrigation_id]\n",
    "                \n",
    "            indices = yield_pf.index.tolist()\n",
    "            img_list = [img_list[i] for i in indices]\n",
    "            #### yield_pf = yield_pf[yield_pf['Variety_int'] == analyze_variety_id & yield_pf['Irrigation_int'] == analyze_irrigation_id]\n",
    "            yield_pf = yield_pf.reset_index(drop=True)\n",
    "\n",
    "        yield_list = list(yield_pf['Yield_Bu_Ac'])\n",
    "\n",
    "        '''get metadata'''\n",
    "        metadata = create_metadata(yield_pf, weather_file,doy)\n",
    "\n",
    "\n",
    "        meta_df = pd.concat([meta_df, metadata], ignore_index=True)\n",
    "        yield_pf_all = pd.concat([yield_pf_all, yield_pf], ignore_index=True)\n",
    "        all_img_list.extend(img_list)\n",
    "        all_yield_list.extend(yield_list)\n",
    "\n",
    "    return all_img_list, all_yield_list, meta_df, yield_pf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word_list = ['Ref_filled.tif']\n",
    "analyze_variety_id = 3\n",
    "analyze_irrigation_id = 2\n",
    "train_col='TRAIN_70'\n",
    "for keyword in key_word_list:\n",
    "\n",
    "    \n",
    "    # img_list, yield_list, metadata, yield_pf  = get_multi_data(img_path_list, yield_file,keyword,doy_list, analyze_variety_id, analyze_irrigation_id)\n",
    "\n",
    "    img_list, yield_list, metadata, yield_pf = get_multi_data([img_path], yield_file,keyword,[doy], analyze_variety_id, analyze_irrigation_id)\n",
    "\n",
    "    # VI_list = ['evi', 'ndvi', 'ndre', 'gndvi']\n",
    "    # VI_list = ['evi', 'ndvi']\n",
    "    # suffix_list = ['LWIR_filled.tif']\n",
    "# \n",
    "    VI_list = None\n",
    "    suffix_list = None\n",
    "    # print(metadata)\n",
    "    # train_val_dataset = MixedDataset(img_list, yield_list, metadata)\n",
    "\n",
    "        # Use train_test_split to split the indices into training and testing sets\n",
    "    # train_indices, test_indices = train_test_split(range(len(img_list)), test_size=test_size, random_state=39)\n",
    "    train_indices = list(yield_pf[yield_pf[train_col] == 1].index)\n",
    "    test_indices = list(yield_pf[yield_pf[train_col] == 0].index)\n",
    "\n",
    "    print(len(train_indices), len(test_indices))\n",
    "\n",
    "\n",
    "    train_val_dataset = MixedDataset([img_list[i] for i in train_indices], [yield_list[i] for i in train_indices], metadata.loc[train_indices], VI_list=VI_list, suffix_list=suffix_list,  transform=data_transform())\n",
    "    test_dataset = MixedDataset([img_list[i] for i in test_indices], [yield_list[i] for i in test_indices], metadata.loc[test_indices], suffix_list=suffix_list, VI_list=VI_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dl.model import ResNetFNN, ResNetFNN_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "in_channel = 5\n",
    "num_epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize an empty list to store fold-wise performance\n",
    "fold_accuracies = []\n",
    "resname='resnet18'\n",
    "# Initialize a new model for each fold\n",
    "# model = CNNRegression(in_channel)\n",
    "# model = ResNetFNN(in_channel,9,1)\n",
    "model = ResNetFNN_V2(in_channel,9,1,resname)\n",
    "# model = EncoderCNN(in_channel, 1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # Mean Squared Error loss function\n",
    "# optimizer = optim.Adam(list(conv.parameters()) + list(deconv.parameters()), lr=0.001)  # Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = train_with_cross_validation(model, train_val_dataset, batch_size, num_epochs, optimizer, criterion, is_dual_data=True)\n",
    "\n",
    "\n",
    "# model_name = \"path/model_img(nbands=\"+str(in_channel)+\")_metadata_\" + crop_var[analyze_variety_id]+\"_\"+ model.__class__.__name__+ img_path[-24:-17] +resname+\"__Batch=\" +str(batch_size) + \"_state.pth\"\n",
    "model_name = \"path/model_img(nbands=\"+str(in_channel)+\")_metadata_\" + crop_var[analyze_variety_id]+\"_\"+ model.__class__.__name__+ '_' +resname+\"__Batch=\" +str(batch_size) + \"_state.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"../output/path/model_metadata_ResNetFNN_DOY186_Batch=32_state.pth\"\n",
    "# # in_channel = 5\n",
    "# # num_epochs = 200\n",
    "# # batch_size = 32\n",
    "\n",
    "# loaded_model = ResNetFNN(in_channel,9,1)\n",
    "# loaded_model.load_state_dict(torch.load(model_name))\n",
    "# loaded_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, test_prediction = validate(model, test_dataset,criterion, batch_size = batch_size, is_return_output = True, is_dual_data=True)\n",
    "test_accuracy = np.sqrt(np.mean(test_accuracy))\n",
    "print(f'validation rmse is {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.ml_predict import plot_result_separate\n",
    "yield_data = np.array(yield_list)\n",
    "irrigate_data = np.array(yield_pf['Irrigation_int'])\n",
    "\n",
    "test_truth = yield_data[test_indices]\n",
    "\n",
    "\n",
    "name_tag = img_path[-23:-17]\n",
    "# name_tag = 'ALL Data'\n",
    "out_name = name_tag + ' ' + crop_var[analyze_variety_id] + ' ' \n",
    "out_name = out_name + keyword[:-11] \n",
    "out_name = out_name + ''\n",
    "\n",
    "plot_result_separate(np.array(test_truth), np.array(test_prediction), test_indices, irrigate_data, out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_result_separate(y_test, y_pred, test_indices, irrigate_data,save_name):\n",
    "    \n",
    "    basename = os.path.basename(save_name)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    x = np.arange(50,300)\n",
    "    plt.plot(x, x, color = 'k', ls='--', alpha=0.7, linewidth=1.25)\n",
    "    \n",
    "    deficit_indices = np.where(irrigate_data == 1)[0]\n",
    "    full_indices = np.where(irrigate_data == 0)[0]\n",
    "    # plt.scatter( y_test, y_pred, label = f'r-squared = {round(r2,2)}, rmse = {round(rmse, 2)}')\n",
    "    plt.scatter( y_test[np.in1d(test_indices, deficit_indices)], \n",
    "                y_pred[np.in1d(test_indices, deficit_indices)],\n",
    "                marker='x', s=25, color = '#bcbd22', label = 'Deficit irrigated')\n",
    "    plt.scatter( y_test[np.in1d(test_indices, full_indices)], \n",
    "                y_pred[np.in1d(test_indices, full_indices)],\n",
    "                label = 'Fully irrigated', \n",
    "                marker='o', alpha=0.5, s=25, color = '#2ca02c', edgecolors='#2ca02c')\n",
    "    # , facecolor='none'\n",
    "    \n",
    "    plt.xlim([50,300])\n",
    "    plt.ylim([50,300])\n",
    "    plt.xticks(fontname='Times New Roman', size=10)\n",
    "    plt.yticks(fontname='Times New Roman', size=10)\n",
    "    plt.xlabel('True Yield (Bu/Ac)', fontname = 'Times New Roman', fontsize = 12)\n",
    "    plt.ylabel('Predicted Yield (Bu/Ac)', fontname = 'Times New Roman', fontsize = 12)\n",
    "\n",
    "    plt.title(basename, fontname = 'Times New Roman', fontsize = 14)\n",
    "\n",
    "    plt.text(55, 288, f'R-squared = {round(r2,2)}', \n",
    "             fontname = 'Times New Roman', fontsize = 11)\n",
    "    plt.text(55, 275, f'RMSE = {round(rmse, 2)} (Bu/Ac)',  \n",
    "             fontname = 'Times New Roman', fontsize = 11)\n",
    "    \n",
    "    font_props = FontProperties(family='Times New Roman', size=11)\n",
    "    plt.legend(loc='lower right', frameon=False, \n",
    "               prop=font_props)\n",
    "    # yy_pred = model_lasso.predict(X_train)\n",
    "    # plt.scatter(y_train, yy_pred)\n",
    "    plt.savefig(save_name + '.png', dpi=300, bbox_inches='tight')\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(save_name, f' r-squared = {r2}, rmse = {rmse}, mae={mae}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_result_metadata():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
