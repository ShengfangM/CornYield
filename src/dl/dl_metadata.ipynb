{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Specify the new directory path\n",
    "parent_directory = 'D:/Projects/CornYield/src'\n",
    "\n",
    "# Change the current directory\n",
    "os.chdir(parent_directory) \n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_filename_metadata\n",
    "from dl.dl_dataset import MixedDataset\n",
    "from dl.train import train_with_cross_validation, train, validate, data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.model import ResNetRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_file = 'D:/Corn_Yield/BL2022_Yld.csv'\n",
    "weather_file = 'D:/Corn_Yield/CoAgMet ET_VBA_calc_2022.xlsm'\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220616_DOY167_extracted_filled'\n",
    "# out_path = '../output/DOY167/'\n",
    "# doy = 167\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220705_DOY186_extracted_filled'\n",
    "# out_path = '../output/DOY186/'\n",
    "# doy = 186\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "# out_path = '../output/DOY201/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220628_DOY179_extracted_filled'\n",
    "out_path = '../output/DOY179/'\n",
    "doy = 179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_pf = pd.read_excel(weather_file,sheet_name=1, header=[0,1,3])\n",
    "\n",
    "header_name = weather_pf.columns\n",
    "selected_rows = weather_pf[(weather_pf[header_name[-1]] > doy-6) & (weather_pf[header_name[-1]] < doy+6)]\n",
    "\n",
    "air_temperature = selected_rows[header_name[2]].mean()\n",
    "precipitation = selected_rows[header_name[9]].mean()\n",
    "soil_temperature = selected_rows[header_name[10]].mean()\n",
    "soil_temperature2 = selected_rows[header_name[11]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word_list = ['Ref_filled.tif']\n",
    "for keyword in key_word_list:\n",
    "\n",
    "    img_list, yield_pf = get_filename_metadata(img_path, yield_file, keyword)\n",
    "    \n",
    "    yield_list = list(yield_pf['Yield_Bu_Ac'])\n",
    "\n",
    "    # metadata = yield_pf[['Variety_int', 'Irrigation_int']]\n",
    "    metadata = yield_pf[['Variety_int', 'Irrigation_int']]/3\n",
    "    metadata['DOY'] = doy / 366\n",
    "    metadata['Month'] = (doy / 30)/12\n",
    "    metadata['Stage'] = (doy/30 - 5)/5\n",
    "    metadata['air_temperature'] = air_temperature\n",
    "    metadata['precipitation'] = precipitation\n",
    "    metadata['soil_temperature'] = soil_temperature\n",
    "    metadata['soil_temperature2'] = soil_temperature2\n",
    "\n",
    "    indices = yield_pf.index[yield_pf['Variety_int'] == 2].tolist()\n",
    "    yield_list = [yield_list[i] for i in indices]\n",
    "    img_list = [img_list[i] for i in indices]\n",
    "    metadata = metadata[metadata['Variety_int'] == 2/3]\n",
    "    metadata = metadata.reset_index(drop=True)\n",
    "\n",
    "# new_df = df[selected_columns]\n",
    "    # for suffix_list in suffix_list_list:\n",
    "    total_size = len(img_list)\n",
    "    train_size = int(0.8 * total_size)  # 80% for training\n",
    "    test_size = int(0.2 * total_size)   # 20% for validation\n",
    "\n",
    "    # VI_list = ['evi', 'ndvi']\n",
    "    # suffix_list = ['LWIR_filled.tif']\n",
    "# \n",
    "    VI_list = None\n",
    "    suffix_list = None\n",
    "    # print(metadata)\n",
    "    # train_val_dataset = MixedDataset(img_list, yield_list, metadata)\n",
    "\n",
    "        # Use train_test_split to split the indices into training and testing sets\n",
    "    train_indices, test_indices = train_test_split(range(len(img_list)), test_size=test_size, random_state=39)\n",
    "\n",
    "    train_val_dataset = MixedDataset([img_list[i] for i in train_indices], [yield_list[i] for i in train_indices], metadata.loc[train_indices], VI_list=VI_list, suffix_list=suffix_list,  transform=data_transform())\n",
    "    test_dataset = MixedDataset([img_list[i] for i in test_indices], [yield_list[i] for i in test_indices], metadata.loc[test_indices], suffix_list=suffix_list, VI_list=VI_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dl.model import ResNetFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = \"path/model_ResNetRegression_DOY167_Batch=32_state.pth\"\n",
    "# in_channel = 5\n",
    "# batch_size = 32\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "\n",
    "# loaded_model = ResNetRegression(in_channel, 1)\n",
    "# loaded_model.load_state_dict(torch.load(state_dict))\n",
    "\n",
    "# # modules = list(loaded_model.resnet.children())[:-1]\n",
    "# # loaded_model=torch.nn.Sequential(*modules)\n",
    "# # Define a new function for the specific instance\n",
    "# def custom_forward(self, x):\n",
    "#     x = self.resnet.conv1(x)\n",
    "#     x = self.resnet.bn1(x)\n",
    "#     x = self.resnet.relu(x)\n",
    "#     x = self.resnet.maxpool(x)\n",
    "\n",
    "#     x = self.resnet.layer1(x)\n",
    "#     x = self.resnet.layer2(x)\n",
    "#     x = self.resnet.layer3(x)\n",
    "#     x = self.resnet.layer4(x)\n",
    "\n",
    "#     x = self.resnet.avgpool(x)\n",
    "#     x = x.view(x.size(0), -1)\n",
    "#     # x = self.resnet.fc(x)\n",
    "#     return x\n",
    "# loaded_model.forward = custom_forward\n",
    "# loaded_model.to(device)\n",
    "# # Assign the custom function to the instance\n",
    "# # obj.custom_function = custom_function\n",
    "# loaded_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "in_channel = 5\n",
    "num_epochs = 120\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize an empty list to store fold-wise performance\n",
    "fold_accuracies = []\n",
    "\n",
    "# Initialize a new model for each fold\n",
    "# model = CNNRegression(in_channel)\n",
    "model = ResNetFNN(in_channel,9,1)\n",
    "# model = EncoderCNN(in_channel, 1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # Mean Squared Error loss function\n",
    "# optimizer = optim.Adam(list(conv.parameters()) + list(deconv.parameters()), lr=0.001)  # Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation mse is 684.4481643676758\n",
      "validation mse is 507.3188758850098\n",
      "validation mse is 293.1145896911621\n",
      "validation mse is 361.95020904541013\n",
      "validation mse is 428.4539619445801\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = train_with_cross_validation(model, train_val_dataset, batch_size, num_epochs, optimizer, criterion, is_dual_data=True)\n",
    "\n",
    "model_name = \"path/model_metadata_\" + model.__class__.__name__+ img_path[-24:-17] +\"_Batch=\" +str(batch_size) + \"_state.pth\"\n",
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation mse is 19.249476279528565\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, test_prediction = validate(model, test_dataset,criterion, batch_size = batch_size, is_return_output = True, is_dual_data=True)\n",
    "test_accuracy = np.sqrt(np.mean(test_accuracy))\n",
    "print(f'validation mse is {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOY179 Pioneer REF+ Meta CNN  r-squared = 0.8401507853290271, rmse = 19.25511577411272\n"
     ]
    }
   ],
   "source": [
    "from ml.ml_predict import plot_result_separate\n",
    "yield_data = np.array(yield_list)\n",
    "irrigate_data = np.array(yield_pf['Irrigation_int'])\n",
    "\n",
    "test_truth = yield_data[test_indices]\n",
    "\n",
    "\n",
    "name_tag = img_path[-23:-17]\n",
    "out_name = name_tag + ' ' + 'Pioneer' + ' ' \n",
    "out_name = out_name + keyword[:-11].upper() \n",
    "out_name = out_name + '+ Meta CNN'\n",
    "\n",
    "plot_result_separate(np.array(test_truth), np.array(test_prediction), test_indices, irrigate_data, out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_result_metadata():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in test_indices:\n",
    "# #     img = \n",
    "# # batch_size = 1\n",
    "# train_loader = torch.utils.data.DataLoader(train_val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# img_features = []\n",
    "# yield_labels = []\n",
    "# for i, data in enumerate(train_loader, 0):\n",
    "#     inputs, labels = data\n",
    "#     labels = labels.view(-1, 1)\\\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # print(img.shape)\n",
    "#     # print(metadata.shape)\n",
    "#     # print(labels.shape)\n",
    "#     img = img.to(device)\n",
    "#     metadata = metadata.to(device)\n",
    "#     labels = labels.to(device)\n",
    "    \n",
    "#     # Zero the parameter gradients\n",
    "#     optimizer.zero_grad()\n",
    "#     # Forward pass\n",
    "#     outputs = model(img, metadata)\n",
    "    \n",
    "#     # Compute loss\n",
    "#     if  outputs.shape == labels.shape:\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         # Backward pass and optimization\n",
    "#         loss.backward()\n",
    "#         # update weights\n",
    "#         optimizer.step()\n",
    "#     else:\n",
    "#         print('outputs shape is ', outputs.shape, ' the size is ', outputs.size())\n",
    "#         print('labels shape is ', labels.shape, ' the size is ', labels.size())\n",
    "                \n",
    "\n",
    "    \n",
    "\n",
    "#     # Forward pass\n",
    "#     img_feature = loaded_model(loaded_model, inputs)\n",
    "#     img_features.append(img_feature.squeeze().tolist())\n",
    "#     yield_labels.append(labels.squeeze().tolist())\n",
    "    \n",
    "# print(len(img_features))\n",
    "# img_features = np.array(img_features)\n",
    "# yield_labels = np.array(yield_labels)\n",
    "# print(img_features.shape, yield_labels.shape)\n",
    "# original_indices = np.arange(len(yield_labels))\n",
    "# train_images, test_images, train_yields, test_yields, train_indices, test_indices = train_test_split(\n",
    "#     img_features, yield_list, original_indices, test_size=0.2, random_state=39)\n",
    "\n",
    "# all_features = []\n",
    "\n",
    "# img_features = loaded_model()\n",
    "# for img_file in img_list:\n",
    "#     img = read_img(img_file, VI_list = VI_list, \n",
    "#                     suffix_list = suffix_list, is_vi_only=is_vi_only)    \n",
    "#     all_image.append(img)\n",
    "\n",
    "# return np.array(all_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
