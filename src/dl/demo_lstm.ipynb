{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Specify the new directory path\n",
    "parent_directory = 'D:/Projects/CornYield/src'\n",
    "\n",
    "# Change the current directory\n",
    "os.chdir(parent_directory) \n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import select_data_and_yield_list\n",
    "from dl.dl_dataset import CornDatasetTimeSeries\n",
    "from dl.model import ConvLSTMRegression\n",
    "from dl.train import train_with_cross_validation, train, validate, data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../output/DOY161/' already exists.\n"
     ]
    }
   ],
   "source": [
    "yield_file = 'D:/Corn_Yield/BL2022_Yld.csv'\n",
    "img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220610_DOY161_extracted_filled'\n",
    "out_path = '../output/DOY161/'\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220926_DOY269_extracted_filled'\n",
    "# out_path = '../output/DOY269/'\n",
    "if not os.path.exists(out_path):\n",
    "    # If it doesn't exist, create the directory and any missing parent directories\n",
    "    os.makedirs(out_path)\n",
    "    print(f\"Directory '{out_path}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{out_path}' already exists.\")\n",
    "\n",
    "\n",
    "name_tag = img_path[-23:-17]\n",
    "# print(name_tag)\n",
    "\n",
    "# key_word_list = ['Ref_filled.tif', 'RGB_filled.tif']\n",
    "key_word_list = ['Ref_filled.tif']\n",
    "suffix_list_list = [[], ['LWIR_filled.tif']]\n",
    "\n",
    "# suffix = ['base', 'lwir']\n",
    "# suffix_list = ['LWIR_filled.tif']\n",
    "# VI_list = ['ndvi', 'ndre', 'gndvi', 'evi']\n",
    "VI_list = ['evi']\n",
    "for keyword in key_word_list:\n",
    "\n",
    "    selection = ['Pioneer'] # \n",
    "    # selection = 'Pioneer Deficit' \n",
    "    # selection = 'Pioneer Full'\n",
    "    pioneer_img_list, pioneer_yield_list, irrigate_type_list = select_data_and_yield_list(\n",
    "        img_path, yield_file, key_word = keyword, crop_type_select=selection)\n",
    "    \n",
    "    \n",
    "    # for suffix_list in suffix_list_list:\n",
    "    \n",
    "    total_size = len(pioneer_yield_list)\n",
    "    train_size = int(0.8 * total_size)  # 80% for training\n",
    "    test_size = int(0.2 * total_size)   # 20% for validation\n",
    "    \n",
    "    # g = torch.Generator()\n",
    "    # g.manual_seed(39)\n",
    "    \n",
    "    # train_val_dataset, test_dataset = random_split(all_dataset, [train_size, test_size])\n",
    "    \n",
    "    # # all_dataset = CornDataset(pioneer_img_list, pioneer_yield_list, transform = transform)\n",
    "    # all_dataset = CornDatasetTimeSeries(pioneer_img_list, pioneer_yield_list, transform=data_transforms)\n",
    "    \n",
    "    # # Use train_test_split to split the indices into training and testing sets\n",
    "    # train_indices, test_indices = train_test_split(range(len(all_dataset)), test_size=test_size, random_state=39)\n",
    "    # train_val_dataset = torch.utils.data.Subset(all_dataset, train_indices)\n",
    "    # test_dataset = torch.utils.data.Subset(all_dataset, test_indices)\n",
    "    \n",
    "   \n",
    "    # Use train_test_split to split the indices into training and testing sets\n",
    "    train_indices, test_indices = train_test_split(range(len(pioneer_img_list)), test_size=test_size, random_state=39)\n",
    "\n",
    "    train_val_dataset = CornDatasetTimeSeries([pioneer_img_list[i] for i in train_indices], [pioneer_yield_list[i] for i in train_indices], transform=data_transform())\n",
    "    test_dataset = CornDatasetTimeSeries([pioneer_img_list[i] for i in test_indices], [pioneer_yield_list[i] for i in test_indices])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3192\n",
      "<class 'dl.dl_dataset.CornDatasetTimeSeries'>\n"
     ]
    }
   ],
   "source": [
    "print(len(train_val_dataset))\n",
    "print(type(train_val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pioneer_dataset = get_ml_image(pioneer_img_list)\n",
    "    \n",
    "# MEAN = np.nanmean(pioneer_dataset,(0,2,3))\n",
    "# STD = np.nanstd(pioneer_dataset, (0,2,3))\n",
    "# print(MEAN, STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch.optim as optim\n",
    "from dl.model import EncoderCNN, LSTMRegression\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=39)\n",
    "\n",
    "in_channel = 5\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize an empty list to store fold-wise performance\n",
    "fold_accuracies = []\n",
    "\n",
    "# Initialize a new model for each fold\n",
    "embed_size = 256\n",
    "# encoder = EncoderCNN(in_channel, embed_size)\n",
    "# decoder = LSTMRegression(embed_size, 64)\n",
    "model = ConvLSTMRegression(in_channel, 256, 128, 5, 1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# decoder.to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # Mean Squared Error loss function\n",
    "# optimizer = optim.Adam(list(conv.parameters()) + list(deconv.parameters()), lr=0.001)  # Adam optimizer\n",
    "# params = list(decoder.parameters()) + list(encoder.parameters())\n",
    "params = list(model.parameters())\n",
    "optimizer = optim.Adam(params = params, lr=0.001)  # Adam optimizer\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation mse is [2511.2021484375, 2406.32470703125, 2414.206298828125, 2620.45263671875, 2431.562744140625, 2371.388427734375, 2967.73779296875, 2301.8359375, 2267.20849609375, 3175.4599609375, 1634.531982421875, 1896.4498291015625, 1940.7796630859375, 3040.39501953125, 1784.591064453125, 2462.76513671875, 2196.28857421875, 2170.624267578125, 2261.906982421875, 2930.279541015625]\n",
      "validation mse is [2250.3447265625, 1920.94140625, 2120.612548828125, 1724.341064453125, 1994.77978515625, 2810.070556640625, 1398.7020263671875, 2619.2607421875, 2361.29833984375, 2544.627685546875, 2364.96630859375, 2077.87158203125, 1918.868408203125, 1744.46240234375, 2771.3896484375, 2352.07275390625, 1991.145751953125, 2345.749267578125, 2366.456787109375, 2332.54541015625]\n",
      "validation mse is [2409.133544921875, 2490.9365234375, 2390.50634765625, 2721.398193359375, 2199.03271484375, 2052.686279296875, 2013.3387451171875, 2230.34130859375, 2024.6546630859375, 1778.324462890625, 2577.15380859375, 2058.536376953125, 1876.052490234375, 3015.768798828125, 2399.203125, 2452.34765625, 2405.5673828125, 2872.20947265625, 2338.873046875, 2275.964111328125]\n",
      "validation mse is [2585.2392578125, 2016.81982421875, 2270.56201171875, 1744.648681640625, 2628.3623046875, 2699.688720703125, 2257.368896484375, 2366.4599609375, 2499.89111328125, 1732.155029296875, 2711.09033203125, 2335.0625, 1569.106201171875, 2703.51318359375, 2692.38330078125, 2931.98388671875, 2619.3251953125, 2311.0537109375, 2664.129150390625, 2207.0068359375]\n",
      "validation mse is [2483.64892578125, 1723.004638671875, 2241.623291015625, 2095.1044921875, 2239.0634765625, 2543.70361328125, 2216.4052734375, 1917.4765625, 2069.38134765625, 2633.02880859375, 2185.682373046875, 2449.93017578125, 2529.5712890625, 2755.458740234375, 2086.85888671875, 2365.849609375, 2107.756103515625, 2094.57080078125, 1904.0537109375, 2172.1572265625]\n"
     ]
    }
   ],
   "source": [
    "model = train_with_cross_validation(model, train_val_dataset, batch_size, num_epochs, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"path/lstm_model_DOY171_state.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "for train_indices, val_indices in kf.split(train_val_dataset):\n",
    "    train_dataset = torch.utils.data.Subset(train_val_dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(train_val_dataset, val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    # Train your model on the training data\n",
    "    for epoch in range(num_epochs):\n",
    "        # print('start')\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # Get inputs and labels\n",
    "            inputs, labels = data\n",
    "            # print(inputs.shape)\n",
    "            # print(labels.shape)\n",
    "            # labels = labels.unsqueeze(1) #change to (32,1)\n",
    "            labels = labels.view(-1, 1)\n",
    "            # print(labels.shape)\n",
    "            \n",
    "            # Move batch of images and captions to GPU if CUDA is available.\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Zero the gradients.\n",
    "            decoder.zero_grad()\n",
    "            encoder.zero_grad()\n",
    "            features = None\n",
    "            # Pass the inputs through the CNN-RNN model.\n",
    "            for step in range(inputs.shape[1]):\n",
    "                # print(step)\n",
    "                feature = encoder(inputs[:,step,:,:])\n",
    "                feature = feature.unsqueeze(1)\n",
    "\n",
    "                if step == 0:\n",
    "                    features = feature\n",
    "                else:\n",
    "                    features = torch.cat([features, feature], dim=1)\n",
    "                # print(features.shape)\n",
    "            \n",
    "            outputs = decoder(features)\n",
    "            del features\n",
    "            # # Calculate the batch loss.\n",
    "            # loss = criterion(outputs, labels)\n",
    "            # # Backward pass.\n",
    "            # loss.backward()\n",
    "            \n",
    "            # # Update the parameters in the optimizer.\n",
    "            # optimizer.step()\n",
    "            \n",
    "            # Compute loss\n",
    "            if  outputs.shape[0] == labels.shape[0]:\n",
    "                loss = criterion(outputs[:,-1].squeeze(), labels[:,-1].squeeze())\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                print('outputs shape is ', outputs.shape, ' the first value is ', outputs[0])\n",
    "                print('labels shape is ', labels.shape, ' the first label is ', labels[0])\n",
    "            \n",
    "            # # Print statistics\n",
    "            # running_loss += loss.item()\n",
    "            # train_loss +=  loss.item()\n",
    "            # if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            #     print('[%d, %5d] loss: %.3f' %\n",
    "            #         (epoch + 1, i + 1, running_loss))\n",
    "            #     running_loss = 0.0\n",
    "\n",
    "\n",
    "    # Evaluate the model on the validation data\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    val_accuracy = []\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        inputs, labels = data\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        # Perform forward and backward passes through the neural network\n",
    "        # optimizer.zero_grad()\n",
    "        features = encoder(inputs)\n",
    "        outputs = decoder(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_accuracy.append(loss.detach().numpy())\n",
    "        \n",
    "        # Evaluation loop\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "    print(f'validation mse is {val_accuracy}')\n",
    "    fold_accuracies.append(val_accuracy)\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "print(f'The final validation mse is {average_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(average_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(average_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_accuracy = []\n",
    "test_pred = []\n",
    "test_truth = []\n",
    "\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "    labels = labels.view(-1, 1)\n",
    "\n",
    "    # Perform forward and backward passes through the neural network\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    # print(outputs.shape)\n",
    "\n",
    "    test_pred.extend(outputs.squeeze().tolist())\n",
    "    test_truth.extend(labels.squeeze().tolist())\n",
    "    loss = criterion(outputs, labels)\n",
    "    # print(outputs.squeeze(), labels.squeeze())\n",
    "    test_accuracy.append(loss.detach().numpy())\n",
    "    \n",
    "    # Evaluation loop\n",
    "test_accuracy2 = np.mean(test_pred)\n",
    "print(f'validation mse is {test_accuracy2}')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_data = np.array(pioneer_yield_list)\n",
    "irrigate_data = np.array(irrigate_type_list)\n",
    "\n",
    "gt2 = yield_data[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_truth - gt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.ml_predict import plot_result, plot_result_separate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(test_truth, test_pred, 'test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deficit_indices = np.where(irrigate_data == 1)[0]\n",
    "full_indices = np.where(irrigate_data == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.in1d(test_indices, deficit_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(irrigate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result_separate(np.array(test_truth), np.array(test_pred), test_indices, irrigate_data, 'test2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = test_dataset\n",
    "print(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-cy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
