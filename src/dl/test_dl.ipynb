{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Specify the new directory path\n",
    "parent_directory = 'C:/Zhou/Ma/Projects/CornYield/src'\n",
    "\n",
    "# Change the current directory\n",
    "os.chdir(parent_directory) \n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_imgfilelist_yield, create_metadata\n",
    "from dl.dl_dataset import MixedDataset\n",
    "from dl.train import train_with_cross_validation, train, validate, data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.model import ResNetRegression_V00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_var={\n",
    "    3: 'all',\n",
    "    2: 'P9998',\n",
    "    1: 'CH 192-10',\n",
    "    0: 'DKC 51-91'\n",
    "}\n",
    "\n",
    "crop_var2={\n",
    "    'all': 'all',\n",
    "    'P9998': 'Pioneer',\n",
    "    'CH 192-10': 'CH',\n",
    "    'DKC 51-91': 'DKC'\n",
    "}\n",
    "seed=42\n",
    "\n",
    "irrigate_var={\n",
    "    2: 'All',\n",
    "    0: 'Full',\n",
    "    1: 'Deficit'\n",
    "}\n",
    "yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld_label.csv'\n",
    "weather_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/CoAgMet ET_VBA_calc_2022.xlsm'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.dl_prediction import predict_yield_from_img, predict_yield_from_img_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld_label.csv'\n",
    "out_path = '../output/'\n",
    "img_root_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/path/' already exists.\n",
      "Directory '../output/' already exists.\n"
     ]
    }
   ],
   "source": [
    "from path_utils import check_path_exist\n",
    "check_path_exist('/path/')\n",
    "check_path_exist(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled\n",
      "5\n",
      "cuda\n",
      "validation mse is 412.3318002635035\n",
      "All validation mse is 412.3318002635035\n",
      "validation mse is 404.2684573469491\n",
      "All validation mse is 396.20511443039464\n",
      "validation mse is 334.2601787523292\n",
      "All validation mse is 194.2436215630893\n",
      "validation mse is 295.60360619734075\n",
      "All validation mse is 179.63388853237547\n",
      "\n",
      "training time is  :  14809.347702980042\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory path does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m img_path \u001b[38;5;241m=\u001b[39m img_root_path\u001b[38;5;241m+\u001b[39mpath_i\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_path)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mpredict_yield_from_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43myield_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mkey_word_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRef_filled.tif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manalyze_variety_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresnet18\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# predict_yield_from_img_metadata(yield_file, img_path, weather_file, out_path, is_save_model=True, key_word_list = ['Ref_filled.tif', 'RGB_filled.tif'], analyze_variety_id = 3,is_test=True)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Zhou\\Ma\\Projects\\CornYield\\src\\dl\\dl_prediction.py:159\u001b[0m, in \u001b[0;36mpredict_yield_from_img\u001b[1;34m(yield_file, img_path, out_path, is_save_model, is_test, analyze_variety_id, analyze_irrigation_id, key_word_list, resname)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_save_model:\n\u001b[0;32m    158\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/model_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m crop_var[analyze_variety_id] \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_img(nbands=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(in_channel)\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(doy_name) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mresname\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Batch=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(batch_size) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Epoch=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(num_epochs) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_lr=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(lr)\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_state.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 159\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m cur_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    162\u001b[0m test_accuracy, test_prediction \u001b[38;5;241m=\u001b[39m validate(model, test_dataset, criterion, batch_size \u001b[38;5;241m=\u001b[39m batch_size, is_return_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Zhou\\Projects\\venv-cy\\lib\\site-packages\\torch\\serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Zhou\\Projects\\venv-cy\\lib\\site-packages\\torch\\serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Zhou\\Projects\\venv-cy\\lib\\site-packages\\torch\\serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory path does not exist."
     ]
    }
   ],
   "source": [
    "\n",
    "# path_list = ['LIRF20220628_DOY179_extracted_filled', 'LIRF20220708_DOY189_extracted_filled', 'LIRF20220716_DOY197_extracted_filled', \\\n",
    "# path_list = ['LIRF20220628_DOY179_extracted_filled', 'LIRF20220708_DOY189_extracted_filled', 'LIRF20220716_DOY197_extracted_filled','LIRF20220720_DOY201_extracted_filled', 'LIRF20220916_DOY259_extracted_filled', 'LIRF20220926_DOY269_extracted_filled']\n",
    "# path_list = ['LIRF20220716_DOY197_extracted_filled']\n",
    "path_list = ['LIRF20220720_DOY201_extracted_filled','LIRF20220705_DOY186_extracted_filled','LIRF20220926_DOY269_extracted_filled']\n",
    "# path_list = ['LIRF20220705_DOY186_extracted_filled', 'LIRF20220720_DOY201_extracted_filled', 'LIRF20220926_DOY269_extracted_filled']\n",
    "# path_list = [ 'LIRF20220705_DOY186_extrac\n",
    "# ted_filled', 'LIRF20220708_DOY189_extracted_filled','LIRF20220610_DOY161_extracted_filled', 'LIRF20220716_DOY197_extracted_filled', 'LIRF20220616_DOY167_extracted_filled']\n",
    "# path_list = ['LIRF20220628_DOY179_extracted_filled', 'LIRF20220708_DOY189_extracted_filled', 'LIRF20220716_DOY197_extracted_filled']\n",
    "# path_list = ['LIRF20220628_DOY179_extracted_filled', 'LIRF20220720_DOY201_extracted_filled', 'LIRF20220916_DOY259_extracted_filled', 'LIRF20220926_DOY269_extracted_filled']\n",
    "\n",
    "for path_i in path_list:\n",
    "    img_path = img_root_path+path_i\n",
    "    print(img_path)\n",
    "    \n",
    "    predict_yield_from_img(yield_file, img_path, out_path, True, True,key_word_list = ['Ref_filled.tif'], analyze_variety_id = 3, resname='resnet18')\n",
    "    # predict_yield_from_img_metadata(yield_file, img_path, weather_file, out_path, is_save_model=True, key_word_list = ['Ref_filled.tif', 'RGB_filled.tif'], analyze_variety_id = 3,is_test=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.model import ResNetRegression_V00, ResNetRegression_V10, ViTRegression_V0, EfficientNetRegression, ResNetRegression_V01\n",
    "from dl.dl_prediction import predict_yield\n",
    "import torch\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220705_DOY186_extracted_filled'\n",
    "img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220716_DOY197_extracted_filled'\n",
    "\n",
    "model_name = \"./path/model_pioneer_img(nbands=3)_DOY197-ResNetRegression_V01resnet18_Batch=32_lr=0.00075_state.pth\"\n",
    "resname = 'resnet18'\n",
    "in_channel = 3\n",
    "# # num_epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "# loaded_model = ResNetFNN_V2(in_channel,9,1,resname)\n",
    "loaded_model = ResNetRegression_V01(in_channel, 1, resname)\n",
    "# loaded_model = ViTRegression_V0(in_channel)\n",
    "loaded_model.load_state_dict(torch.load(model_name))\n",
    "# loaded_model.to(device)    \n",
    "    \n",
    "predict_yield(yield_file, img_path, out_path, loaded_model, key_word_list=['RGB_filled.tif'])\n",
    "    \n",
    "\n",
    "# test_accuracy, test_prediction = validate(loaded_model, test_dataset,criterion, batch_size = batch_size, is_return_output = True, is_dual_data=True)\n",
    "# test_accuracy = np.sqrt(np.mean(test_accuracy))\n",
    "\n",
    "# print(f'validation rmse is {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list=[\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220616_DOY167_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220628_DOY179_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220708_DOY189_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "]\n",
    "doy_list=[167, 179, 189, 201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220610_DOY161_extracted_filled'\n",
    "# out_path = '../output/DOY161/'\n",
    "# doy=161\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220616_DOY167_extracted_filled'\n",
    "# out_path = '../output/DOY167/'\n",
    "# doy = 167\n",
    "img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220705_DOY186_extracted_filled'\n",
    "out_path = '../output/DOY186/'\n",
    "doy = 186\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "# out_path = '../output/DOY201/'\n",
    "# doy=201\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220916_DOY259_extracted_filled'\n",
    "# out_path = '../output/DOY259/'\n",
    "# doy=259\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220708_DOY189_extracted_filled'\n",
    "# out_path = '../output/DOY189/'\n",
    "# doy=189\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220628_DOY179_extracted_filled'\n",
    "# out_path = '../output/DOY179/'\n",
    "# doy = 179\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220716_DOY197_extracted_filled'\n",
    "# out_path = '../output/DOY197/'\n",
    "# doy = 197\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220926_DOY269_extracted_filled'\n",
    "# out_path = '../output/DOY269/'\n",
    "# doy=269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_data(img_path_list, yield_file,keyword,doy_list, analyze_variety_id, analyze_irrigation_id:int=2):\n",
    "    all_img_list = []\n",
    "    all_yield_list = []\n",
    "    meta_df = pd.DataFrame()\n",
    "    # all_train_indices = []\n",
    "    yield_pf_all = pd.DataFrame()\n",
    "    for (img_path,doy) in zip(img_path_list,doy_list):\n",
    "        print(doy)\n",
    "        img_list, yield_pf = get_imgfilelist_yield(img_path, yield_file, keyword)\n",
    "\n",
    "        if analyze_variety_id != 3 or analyze_irrigation_id != 2:\n",
    "            if analyze_variety_id != 3 and analyze_irrigation_id != 2:\n",
    "                yield_pf = yield_pf[(yield_pf['Variety_int'] == analyze_variety_id) & (yield_pf['Irrigation_int'] == analyze_irrigation_id)]\n",
    "            elif analyze_variety_id != 3:\n",
    "                yield_pf = yield_pf[yield_pf['Variety_int'] == analyze_variety_id]\n",
    "            elif  analyze_irrigation_id != 2:\n",
    "                yield_pf = yield_pf[ yield_pf['Irrigation_int'] == analyze_irrigation_id]\n",
    "                \n",
    "            indices = yield_pf.index.tolist()\n",
    "            img_list = [img_list[i] for i in indices]\n",
    "            #### yield_pf = yield_pf[yield_pf['Variety_int'] == analyze_variety_id & yield_pf['Irrigation_int'] == analyze_irrigation_id]\n",
    "            yield_pf = yield_pf.reset_index(drop=True)\n",
    "\n",
    "        yield_list = list(yield_pf['Yield_Bu_Ac'])\n",
    "\n",
    "        '''get metadata'''\n",
    "        metadata = create_metadata(yield_pf, weather_file,doy)\n",
    "\n",
    "\n",
    "        meta_df = pd.concat([meta_df, metadata], ignore_index=True)\n",
    "        yield_pf_all = pd.concat([yield_pf_all, yield_pf], ignore_index=True)\n",
    "        all_img_list.extend(img_list)\n",
    "        all_yield_list.extend(yield_list)\n",
    "\n",
    "    return all_img_list, all_yield_list, meta_df, yield_pf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word_list = ['Ref_filled.tif']\n",
    "analyze_variety_id = 2\n",
    "analyze_irrigation_id = 2\n",
    "train_col='TRAIN_75'\n",
    "for keyword in key_word_list:\n",
    "\n",
    "    \n",
    "    img_list, yield_list, metadata, yield_pf  = get_multi_data(img_path_list, yield_file,keyword,doy_list, analyze_variety_id, analyze_irrigation_id)\n",
    "\n",
    "    # img_list, yield_list, metadata, yield_pf = get_multi_data([img_path], yield_file,keyword,[doy], analyze_variety_id, analyze_irrigation_id)\n",
    "\n",
    "    # VI_list = ['evi', 'ndvi', 'ndre', 'gndvi']\n",
    "    # VI_list = ['evi', 'ndvi']\n",
    "    # suffix_list = ['LWIR_filled.tif']\n",
    "# \n",
    "    VI_list = None\n",
    "    suffix_list = None\n",
    "    \n",
    "    # Use train_test_split to split the indices into training and testing sets\n",
    "    # train_indices, test_indices = train_test_split(range(len(img_list)), test_size=test_size, random_state=39)\n",
    "    train_indices = list(yield_pf[yield_pf[train_col] == 1].index)\n",
    "    test_indices = list(yield_pf[yield_pf[train_col] == 0].index)\n",
    "\n",
    "    train_val_dataset = MixedDataset([img_list[i] for i in train_indices], [yield_list[i] for i in train_indices], metadata.loc[train_indices], VI_list=VI_list, suffix_list=suffix_list,  transform=data_transform())\n",
    "    test_dataset = MixedDataset([img_list[i] for i in test_indices], [yield_list[i] for i in test_indices], metadata.loc[test_indices], suffix_list=suffix_list, VI_list=VI_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dl.model import ResNetFNN, ResNetFNN_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "in_channel = 5\n",
    "num_epochs = 120\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize an empty list to store fold-wise performance\n",
    "fold_accuracies = []\n",
    "resname='resnet18'\n",
    "# Initialize a new model for each fold\n",
    "# model = CNNRegression(in_channel)\n",
    "# model = ResNetFNN(in_channel,9,1)\n",
    "# model = ResNetFNN_V2(in_channel,9,1,resname)\n",
    "model = ResNetRegression(in_channel, 1, resname)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # Mean Squared Error loss function\n",
    "# optimizer = optim.Adam(list(conv.parameters()) + list(deconv.parameters()), lr=0.001)  # Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = train_with_cross_validation(model, train_val_dataset, batch_size, num_epochs, optimizer, criterion, is_dual_data=True)\n",
    "\n",
    "\n",
    "# model_name = \"path/model_img(nbands=\"+str(in_channel)+\")_metadata_\" + crop_var[analyze_variety_id]+\"_\"+ model.__class__.__name__+ img_path[-24:-17] +resname+\"__Batch=\" +str(batch_size) + \"_state.pth\"\n",
    "model_name = \"path/model_img(nbands=\"+str(in_channel)+\")_metadata_\" + crop_var[analyze_variety_id]+\"_\"+irrigate_var[analyze_irrigation_id]+\"_\"+ model.__class__.__name__+ '_' +resname+\"__Batch=\" +str(batch_size) + \"_state.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, test_prediction = validate(model, test_dataset,criterion, batch_size = batch_size, is_return_output = True, is_dual_data=True)\n",
    "test_accuracy = np.sqrt(np.mean(test_accuracy))\n",
    "\n",
    "print(f'validation rmse is {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.ml_predict import plot_result_separate\n",
    "from plot_utils import plot_distinct_yields\n",
    "\n",
    "yield_data = np.array(yield_list)\n",
    "test_irrigate_data = np.array(yield_pf[yield_pf[train_col] == 0]['Irrigation_int'])\n",
    "test_variety_data = np.array(yield_pf[yield_pf[train_col] == 0]['Variety_int'])\n",
    "\n",
    "test_truth = yield_data[test_indices]\n",
    "\n",
    "# deficit_indices = list(yield_pf[yield_pf[train_col] == 1].index)\n",
    "# test_indices = list(yield_pf[yield_pf[train_col] == 0].index)\n",
    "\n",
    "name_tag = img_path[-23:-17]\n",
    "# name_tag = 'ALL Data'\n",
    "out_name = name_tag \n",
    "out_name = out_name + ' ' + crop_var[analyze_variety_id] + ' ' + irrigate_var[analyze_irrigation_id]\n",
    "out_name = out_name + keyword[:-11] \n",
    "out_name = out_name + ''\n",
    "\n",
    "title = name_tag + ' ' + keyword[:-11].upper()\n",
    "\n",
    "\n",
    "result_df=pd.DataFrame({\n",
    "    'Truth': np.array(test_truth), \n",
    "    'Prediction':np.array(test_prediction),\n",
    "    'Irrigation_int':test_irrigate_data,\n",
    "    'Vriaty_int':test_variety_data\n",
    "})\n",
    "csv_file_path = out_name + '.csv'\n",
    "result_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "\n",
    "plot_distinct_yields(np.array(test_truth), np.array(test_prediction), test_irrigate_data, test_variety_data, title, out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "crop_var[analyze_variety_id]    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
