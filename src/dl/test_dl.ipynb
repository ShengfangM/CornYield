{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Specify the new directory path\n",
    "parent_directory = 'C:/Zhou/Ma/Projects/CornYield/src'\n",
    "\n",
    "# Change the current directory\n",
    "os.chdir(parent_directory) \n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_imgfilelist_yield, create_metadata\n",
    "from dl.dl_dataset import MixedDataset\n",
    "from dl.train import train_with_cross_validation, train, validate, data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.model import ResNetRegression_V00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_var={\n",
    "    3: 'all',\n",
    "    2: 'P9998',\n",
    "    1: 'CH 192-10',\n",
    "    0: 'DKC 51-91'\n",
    "}\n",
    "\n",
    "crop_var2={\n",
    "    'all': 'all',\n",
    "    'P9998': 'Pioneer',\n",
    "    'CH 192-10': 'CH',\n",
    "    'DKC 51-91': 'DKC'\n",
    "}\n",
    "seed=42\n",
    "\n",
    "irrigate_var={\n",
    "    2: 'All',\n",
    "    0: 'Full',\n",
    "    1: 'Deficit'\n",
    "}\n",
    "yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld_label.csv'\n",
    "weather_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/CoAgMet ET_VBA_calc_2022.xlsm'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.dl_prediction import predict_yield_from_img, predict_yield_from_img_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld_label.csv'\n",
    "out_path = '../output/'\n",
    "img_root_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/path/' already exists.\n",
      "Directory '../output/' already exists.\n"
     ]
    }
   ],
   "source": [
    "from path_utils import check_path_exist\n",
    "check_path_exist('/path/')\n",
    "check_path_exist(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled\n",
      "5\n",
      "cuda\n",
      "validation mse is 215.5583372116089\n",
      "All validation mse is 215.5583372116089\n",
      "validation mse is 208.54275941848755\n",
      "All validation mse is 201.5271816253662\n",
      "validation mse is 230.84142674340143\n",
      "All validation mse is 275.4387613932292\n",
      "validation mse is 219.69277715682983\n",
      "All validation mse is 186.24682839711508\n",
      "\n",
      "training time is  :  12180.150736808777\n",
      "\n",
      "validation mse is 13.806258763612286\n",
      "\n",
      "test time is  :  6.866801500320435\n",
      "\n",
      "../output/DOY201 Pioneer   Ref Resnet18   r-squared = 0.9165471691555516, rmse = 13.87614919433576, mae=9.87457986927071\n",
      "3\n",
      "cuda\n",
      "validation mse is 281.16989580790204\n",
      "All validation mse is 281.16989580790204\n",
      "validation mse is 256.90965366363525\n",
      "All validation mse is 232.6494115193685\n",
      "validation mse is 279.85091548495825\n",
      "All validation mse is 325.7334391276042\n",
      "validation mse is 259.43141476313275\n",
      "All validation mse is 198.17291259765625\n",
      "\n",
      "training time is  :  7305.908199071884\n",
      "\n",
      "validation mse is 14.33587590757854\n",
      "\n",
      "test time is  :  6.582898139953613\n",
      "\n",
      "../output/DOY201 Pioneer   RGB Resnet18   r-squared = 0.9100035269323519, rmse = 14.409906704684545, mae=10.502518166204359\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# path_list = ['LIRF20220628_DOY179_extracted_filled', 'LIRF20220708_DOY189_extracted_filled', 'LIRF20220716_DOY197_extracted_filled', \\\n",
    "# path_list = ['LIRF20220628_DOY179_extracted_filled', 'LIRF20220708_DOY189_extracted_filled', 'LIRF20220716_DOY197_extracted_filled','LIRF20220720_DOY201_extracted_filled', 'LIRF20220916_DOY259_extracted_filled', 'LIRF20220926_DOY269_extracted_filled']\n",
    "# path_list = ['LIRF20220716_DOY197_extracted_filled']\n",
    "path_list = ['LIRF20220720_DOY201_extracted_filled']\n",
    "# path_list = ['LIRF20220705_DOY186_extracted_filled']\n",
    "# path_list = [ 'LIRF20220705_DOY186_extracted_filled', 'LIRF20220708_DOY189_extracted_filled','LIRF20220610_DOY161_extracted_filled', 'LIRF20220716_DOY197_extracted_filled', 'LIRF20220616_DOY167_extracted_filled']\n",
    "# path_list = ['LIRF20220628_DOY179_extracted_filled', 'LIRF20220708_DOY189_extracted_filled', 'LIRF20220716_DOY197_extracted_filled']\n",
    "# path_list = ['LIRF20220628_DOY179_extracted_filled', 'LIRF20220720_DOY201_extracted_filled', 'LIRF20220916_DOY259_extracted_filled', 'LIRF20220926_DOY269_extracted_filled']\n",
    "\n",
    "for path_i in path_list:\n",
    "    img_path = img_root_path+path_i\n",
    "    print(img_path)\n",
    "    \n",
    "    predict_yield_from_img(yield_file, img_path, out_path, True, True,key_word_list = ['Ref_filled.tif', 'RGB_filled.tif'], resname='resnet18')\n",
    "    # predict_yield_from_img_metadata(yield_file, img_path, weather_file, out_path, is_save_model=True, key_word_list = ['Ref_filled.tif', 'RGB_filled.tif'], is_test=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl.model import ResNetRegression_V00, ResNetRegression_V10, ViTRegression_V0, EfficientNetRegression, ResNetRegression_V01\n",
    "from dl.dl_prediction import predict_yield\n",
    "import torch\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220705_DOY186_extracted_filled'\n",
    "img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220716_DOY197_extracted_filled'\n",
    "\n",
    "model_name = \"./path/model_pioneer_img(nbands=3)_DOY197-ResNetRegression_V01resnet18_Batch=32_lr=0.00075_state.pth\"\n",
    "resname = 'resnet18'\n",
    "in_channel = 3\n",
    "# # num_epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "# loaded_model = ResNetFNN_V2(in_channel,9,1,resname)\n",
    "loaded_model = ResNetRegression_V01(in_channel, 1, resname)\n",
    "# loaded_model = ViTRegression_V0(in_channel)\n",
    "loaded_model.load_state_dict(torch.load(model_name))\n",
    "# loaded_model.to(device)    \n",
    "    \n",
    "predict_yield(yield_file, img_path, out_path, loaded_model, key_word_list=['RGB_filled.tif'])\n",
    "    \n",
    "\n",
    "# test_accuracy, test_prediction = validate(loaded_model, test_dataset,criterion, batch_size = batch_size, is_return_output = True, is_dual_data=True)\n",
    "# test_accuracy = np.sqrt(np.mean(test_accuracy))\n",
    "\n",
    "# print(f'validation rmse is {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list=[\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220616_DOY167_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220628_DOY179_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220708_DOY189_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "]\n",
    "doy_list=[167, 179, 189, 201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220610_DOY161_extracted_filled'\n",
    "# out_path = '../output/DOY161/'\n",
    "# doy=161\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220616_DOY167_extracted_filled'\n",
    "# out_path = '../output/DOY167/'\n",
    "# doy = 167\n",
    "img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220705_DOY186_extracted_filled'\n",
    "out_path = '../output/DOY186/'\n",
    "doy = 186\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "# out_path = '../output/DOY201/'\n",
    "# doy=201\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220916_DOY259_extracted_filled'\n",
    "# out_path = '../output/DOY259/'\n",
    "# doy=259\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220708_DOY189_extracted_filled'\n",
    "# out_path = '../output/DOY189/'\n",
    "# doy=189\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220628_DOY179_extracted_filled'\n",
    "# out_path = '../output/DOY179/'\n",
    "# doy = 179\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220716_DOY197_extracted_filled'\n",
    "# out_path = '../output/DOY197/'\n",
    "# doy = 197\n",
    "\n",
    "# img_path = 'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220926_DOY269_extracted_filled'\n",
    "# out_path = '../output/DOY269/'\n",
    "# doy=269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_data(img_path_list, yield_file,keyword,doy_list, analyze_variety_id, analyze_irrigation_id:int=2):\n",
    "    all_img_list = []\n",
    "    all_yield_list = []\n",
    "    meta_df = pd.DataFrame()\n",
    "    # all_train_indices = []\n",
    "    yield_pf_all = pd.DataFrame()\n",
    "    for (img_path,doy) in zip(img_path_list,doy_list):\n",
    "        print(doy)\n",
    "        img_list, yield_pf = get_imgfilelist_yield(img_path, yield_file, keyword)\n",
    "\n",
    "        if analyze_variety_id != 3 or analyze_irrigation_id != 2:\n",
    "            if analyze_variety_id != 3 and analyze_irrigation_id != 2:\n",
    "                yield_pf = yield_pf[(yield_pf['Variety_int'] == analyze_variety_id) & (yield_pf['Irrigation_int'] == analyze_irrigation_id)]\n",
    "            elif analyze_variety_id != 3:\n",
    "                yield_pf = yield_pf[yield_pf['Variety_int'] == analyze_variety_id]\n",
    "            elif  analyze_irrigation_id != 2:\n",
    "                yield_pf = yield_pf[ yield_pf['Irrigation_int'] == analyze_irrigation_id]\n",
    "                \n",
    "            indices = yield_pf.index.tolist()\n",
    "            img_list = [img_list[i] for i in indices]\n",
    "            #### yield_pf = yield_pf[yield_pf['Variety_int'] == analyze_variety_id & yield_pf['Irrigation_int'] == analyze_irrigation_id]\n",
    "            yield_pf = yield_pf.reset_index(drop=True)\n",
    "\n",
    "        yield_list = list(yield_pf['Yield_Bu_Ac'])\n",
    "\n",
    "        '''get metadata'''\n",
    "        metadata = create_metadata(yield_pf, weather_file,doy)\n",
    "\n",
    "\n",
    "        meta_df = pd.concat([meta_df, metadata], ignore_index=True)\n",
    "        yield_pf_all = pd.concat([yield_pf_all, yield_pf], ignore_index=True)\n",
    "        all_img_list.extend(img_list)\n",
    "        all_yield_list.extend(yield_list)\n",
    "\n",
    "    return all_img_list, all_yield_list, meta_df, yield_pf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word_list = ['Ref_filled.tif']\n",
    "analyze_variety_id = 2\n",
    "analyze_irrigation_id = 2\n",
    "train_col='TRAIN_75'\n",
    "for keyword in key_word_list:\n",
    "\n",
    "    \n",
    "    img_list, yield_list, metadata, yield_pf  = get_multi_data(img_path_list, yield_file,keyword,doy_list, analyze_variety_id, analyze_irrigation_id)\n",
    "\n",
    "    # img_list, yield_list, metadata, yield_pf = get_multi_data([img_path], yield_file,keyword,[doy], analyze_variety_id, analyze_irrigation_id)\n",
    "\n",
    "    # VI_list = ['evi', 'ndvi', 'ndre', 'gndvi']\n",
    "    # VI_list = ['evi', 'ndvi']\n",
    "    # suffix_list = ['LWIR_filled.tif']\n",
    "# \n",
    "    VI_list = None\n",
    "    suffix_list = None\n",
    "    \n",
    "    # Use train_test_split to split the indices into training and testing sets\n",
    "    # train_indices, test_indices = train_test_split(range(len(img_list)), test_size=test_size, random_state=39)\n",
    "    train_indices = list(yield_pf[yield_pf[train_col] == 1].index)\n",
    "    test_indices = list(yield_pf[yield_pf[train_col] == 0].index)\n",
    "\n",
    "    train_val_dataset = MixedDataset([img_list[i] for i in train_indices], [yield_list[i] for i in train_indices], metadata.loc[train_indices], VI_list=VI_list, suffix_list=suffix_list,  transform=data_transform())\n",
    "    test_dataset = MixedDataset([img_list[i] for i in test_indices], [yield_list[i] for i in test_indices], metadata.loc[test_indices], suffix_list=suffix_list, VI_list=VI_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dl.model import ResNetFNN, ResNetFNN_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "in_channel = 5\n",
    "num_epochs = 120\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize an empty list to store fold-wise performance\n",
    "fold_accuracies = []\n",
    "resname='resnet18'\n",
    "# Initialize a new model for each fold\n",
    "# model = CNNRegression(in_channel)\n",
    "# model = ResNetFNN(in_channel,9,1)\n",
    "# model = ResNetFNN_V2(in_channel,9,1,resname)\n",
    "model = ResNetRegression(in_channel, 1, resname)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # Mean Squared Error loss function\n",
    "# optimizer = optim.Adam(list(conv.parameters()) + list(deconv.parameters()), lr=0.001)  # Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = train_with_cross_validation(model, train_val_dataset, batch_size, num_epochs, optimizer, criterion, is_dual_data=True)\n",
    "\n",
    "\n",
    "# model_name = \"path/model_img(nbands=\"+str(in_channel)+\")_metadata_\" + crop_var[analyze_variety_id]+\"_\"+ model.__class__.__name__+ img_path[-24:-17] +resname+\"__Batch=\" +str(batch_size) + \"_state.pth\"\n",
    "model_name = \"path/model_img(nbands=\"+str(in_channel)+\")_metadata_\" + crop_var[analyze_variety_id]+\"_\"+irrigate_var[analyze_irrigation_id]+\"_\"+ model.__class__.__name__+ '_' +resname+\"__Batch=\" +str(batch_size) + \"_state.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, test_prediction = validate(model, test_dataset,criterion, batch_size = batch_size, is_return_output = True, is_dual_data=True)\n",
    "test_accuracy = np.sqrt(np.mean(test_accuracy))\n",
    "\n",
    "print(f'validation rmse is {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.ml_predict import plot_result_separate\n",
    "from plot_utils import plot_distinct_yields\n",
    "\n",
    "yield_data = np.array(yield_list)\n",
    "test_irrigate_data = np.array(yield_pf[yield_pf[train_col] == 0]['Irrigation_int'])\n",
    "test_variety_data = np.array(yield_pf[yield_pf[train_col] == 0]['Variety_int'])\n",
    "\n",
    "test_truth = yield_data[test_indices]\n",
    "\n",
    "# deficit_indices = list(yield_pf[yield_pf[train_col] == 1].index)\n",
    "# test_indices = list(yield_pf[yield_pf[train_col] == 0].index)\n",
    "\n",
    "name_tag = img_path[-23:-17]\n",
    "# name_tag = 'ALL Data'\n",
    "out_name = name_tag \n",
    "out_name = out_name + ' ' + crop_var[analyze_variety_id] + ' ' + irrigate_var[analyze_irrigation_id]\n",
    "out_name = out_name + keyword[:-11] \n",
    "out_name = out_name + ''\n",
    "\n",
    "title = name_tag + ' ' + keyword[:-11].upper()\n",
    "\n",
    "\n",
    "result_df=pd.DataFrame({\n",
    "    'Truth': np.array(test_truth), \n",
    "    'Prediction':np.array(test_prediction),\n",
    "    'Irrigation_int':test_irrigate_data,\n",
    "    'Vriaty_int':test_variety_data\n",
    "})\n",
    "csv_file_path = out_name + '.csv'\n",
    "result_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "\n",
    "plot_distinct_yields(np.array(test_truth), np.array(test_prediction), test_irrigate_data, test_variety_data, title, out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "crop_var[analyze_variety_id]    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
