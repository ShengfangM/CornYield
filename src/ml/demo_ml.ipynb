{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440b6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b85590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the new directory path\n",
    "parent_directory = 'c:/Zhou/Ma/Projects/CornYield/src'\n",
    "\n",
    "# Change the current directory\n",
    "os.chdir(parent_directory) \n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e415bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338a8fd",
   "metadata": {},
   "source": [
    "1. read yield data and filled img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960958f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import select_data_and_yield_list, get_ml_image\n",
    "from ml.ml_predict import ml_predict_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dea2cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../output/DOY186/' already exists.\n",
      "../output/DOY186/DOY186 Pioneer Ref+NDVI+EVI Lasso  r-squared = 0.6612496920578974, rmse = 28.030492605876994\n",
      "../output/DOY186/DOY186 Pioneer Ref+NDVI+EVI LR  r-squared = 0.3671624629430612, rmse = 38.31219165387427\n",
      "../output/DOY186/DOY186 Pioneer Ref+NDVI+EVI RF  r-squared = 0.8216028064736457, rmse = 20.34158968090347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Zhou\\Projects\\venv-cy\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+03, tolerance: 7.362e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/DOY186/DOY186 Pioneer Ref+NDVI+EVI+LWIR Lasso  r-squared = 0.6937678697111719, rmse = 26.65116870977265\n",
      "../output/DOY186/DOY186 Pioneer Ref+NDVI+EVI+LWIR LR  r-squared = 0.33279008042395264, rmse = 39.33889239305652\n",
      "../output/DOY186/DOY186 Pioneer Ref+NDVI+EVI+LWIR RF  r-squared = 0.8399875691642787, rmse = 19.264943611955186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld.csv'\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220716_DOY197_extracted_filled'\n",
    "# out_path = '../output/DOY197/'\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220705_DOY186_extracted_filled'\n",
    "# out_path = '../output/DOY186/'\n",
    "img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220628_DOY179_extracted_filled'\n",
    "out_path = '../output/DOY179/'\n",
    "if not os.path.exists(out_path):\n",
    "    # If it doesn't exist, create the directory and any missing parent directories\n",
    "    os.makedirs(out_path)\n",
    "    print(f\"Directory '{out_path}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{out_path}' already exists.\")\n",
    "\n",
    "name_tag = img_path[-23:-17]\n",
    "# print(name_tag)\n",
    "\n",
    "# key_word_list = ['Ref_filled.tif', 'RGB_filled.tif']\n",
    "key_word_list = ['Ref_filled.tif']\n",
    "suffix_list_list = [[], ['LWIR_filled.tif']]\n",
    "\n",
    "# suffix = ['base', 'lwir']\n",
    "# suffix_list = ['LWIR_filled.tif']\n",
    "# VI_list = ['ndvi', 'ndre', 'gndvi', 'evi']\n",
    "# VI_list = ['ndvi']\n",
    "VI_list = ['ndvi',  'evi']\n",
    "vi_only = False\n",
    "for keyword in key_word_list:\n",
    "\n",
    "    selection = ['Pioneer'] # \n",
    "    # selection = 'Pioneer Deficit' \n",
    "    # selection = 'Pioneer Full'\n",
    "    pioneer_img_list, pioneer_yield_list, irrigate_type_list = select_data_and_yield_list(\n",
    "        img_path, yield_file, key_word = keyword, crop_type_select=selection)\n",
    "    \n",
    "    for suffix_list in suffix_list_list:\n",
    "\n",
    "        pioneer_dataset = get_ml_image(pioneer_img_list, VI_list=VI_list, \n",
    "                                       suffix_list = suffix_list, is_vi_only=vi_only)\n",
    "        \n",
    "        # break\n",
    "        pioneer_yield = np.array(pioneer_yield_list)\n",
    "        irrigate_data = np.array(irrigate_type_list)\n",
    "        # index_pivot = 1740\n",
    "        # deficit_indices = np.where(irrigate_data == 1)[0]\n",
    "        # test_deficit_indices = np.in1d(test_indices, deficit_indices)\n",
    "        \n",
    "        # test_modes = ['Lasso', 'RF']\n",
    "        test_modes = ['Lasso', 'LR', 'RF']\n",
    "        # test_modes = ['Lasso', 'LR', 'SVR', 'GB']\n",
    "        for modelname in test_modes:\n",
    "            \n",
    "            out_name = name_tag + ' ' + 'Pioneer' + ' ' \n",
    "            if not vi_only:\n",
    "                out_name = out_name + keyword[:-11] \n",
    "            for vi_name in VI_list:\n",
    "                out_name = out_name + '+' + vi_name.upper()\n",
    "            for suf in suffix_list:\n",
    "                out_name = out_name + '+' + suf[:-11]\n",
    "            out_name = out_name + ' '\n",
    "            ml_predict_yield(pioneer_dataset, pioneer_yield, irrigate_data, modelname, out_name, out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bacf58",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72c9a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab2f8fdc",
   "metadata": {},
   "source": [
    "index_pivot = 1740\n",
    "deficit_indices = np.where(irrigate_data == 1)[0]\n",
    "test_deficit_indices = np.in1d(test_indices, deficit_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9238b22",
   "metadata": {},
   "source": [
    "## NDVI only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65347a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld.csv'\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220926_DOY269_extracted_filled'\n",
    "# out_path = 'output/'\n",
    "\n",
    "# name_tag = img_path[-23:-17]\n",
    "# # print(name_tag)\n",
    "\n",
    "# selection = 'Pioneer' # \n",
    "# # selection = 'Pioneer Deficit' \n",
    "# # selection = 'Pioneer Full'\n",
    "# key_word_list = ['Ref_filled.tif']\n",
    "# suffix_list_list = [None, ['LWIR_filled.tif']]\n",
    "\n",
    "# # suffix = ['base', 'lwir']\n",
    "# # suffix_list = ['LWIR_filled.tif']\n",
    "# VI_list = ['ndvi']\n",
    "# for keyword in key_word_list: \n",
    "#     pioneer_img_list, pioneer_yield_list = select_data_and_yield_list(img_path, yield_file, key_word = keyword, selection = selection)\n",
    "\n",
    "#     for suffix_list in suffix_list_list:\n",
    "\n",
    "        \n",
    "#         pioneer_dataset = get_ml_image(pioneer_img_list, VI_list = VI_list, suffix_list = suffix_list)\n",
    "#         print(pioneer_dataset.shape\n",
    "#                 )\n",
    "#         pioneer_yield = np.array(pioneer_yield_list)\n",
    "        \n",
    "#         test_modes = ['Lasso', 'LR', 'RF']\n",
    "#         # test_modes = ['Lasso']\n",
    "#         for modelname in test_modes:\n",
    "            \n",
    "#             # out_name = name_tag + ' ' + selection + ' ' + keyword[:-11] + ' NDVI ' \n",
    "#             out_name = name_tag + ' ' + selection + ' NDVI '  \n",
    "#             if suffix_list is not None:\n",
    "#                 for suf in suffix_list:\n",
    "#                     out_name = out_name + suf[:-11]\n",
    "#             out_name = out_name + ' '\n",
    "#             ml_predict_yield(pioneer_dataset, pioneer_yield, modelname, out_name, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ef25a",
   "metadata": {},
   "source": [
    "### load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from ml.ml_predict import test_model\n",
    "\n",
    "import pickle\n",
    "model_name = 'output\\DOY197\\DOY197 Pioneer +NDVI RF.pkl'\n",
    "# Load the model from the .pkl file using pickle\n",
    "with open(model_name, 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "    \n",
    "    \n",
    "vi_only = True    \n",
    "yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld.csv'\n",
    "img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "out_path = 'output/LIRF20220720'\n",
    "\n",
    "name_tag = img_path[-23:-17]\n",
    "# print(name_tag)\n",
    "\n",
    "# key_word_list = ['Ref_filled.tif', 'RGB_filled.tif']\n",
    "key_word_list = ['Ref_filled.tif']\n",
    "suffix_list_list = [[], ['LWIR_filled.tif']]\n",
    "\n",
    "# suffix = ['base', 'lwir']\n",
    "# suffix_list = ['LWIR_filled.tif']\n",
    "# VI_list = ['ndvi', 'ndre', 'gndvi', 'evi']\n",
    "VI_list = ['ndvi']\n",
    "\n",
    "\n",
    "selection = ['Pioneer'] # \n",
    "# selection = 'Pioneer Deficit' \n",
    "# selection = 'Pioneer Full'\n",
    "pioneer_img_list, pioneer_yield_list, irrigate_type_list = select_data_and_yield_list(\n",
    "    img_path, yield_file, key_word = 'Ref_filled.tif', crop_type_select=selection)\n",
    "\n",
    "\n",
    "dataset = get_ml_image(pioneer_img_list, VI_list=VI_list, suffix_list = [], is_vi_only=vi_only)\n",
    "\n",
    "# break\n",
    "yield_data = np.array(pioneer_yield_list)\n",
    "irrigate_data = np.array(irrigate_type_list)\n",
    "\n",
    "    \n",
    "original_indices = np.arange(len(yield_data))\n",
    "train_images, test_images, train_yields, test_yields, train_indices, test_indices = train_test_split(\n",
    "dataset, yield_data, original_indices, test_size=0.2, random_state=39)\n",
    "\n",
    "test_model(model, test_images, test_yields, test_indices, irrigate_data, 'output/apply_model_test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_estimator = model.named_steps['classifier']\n",
    "# # Access feature importances\n",
    "# feature_importances = final_estimator.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc3be1",
   "metadata": {},
   "source": [
    "### get \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld.csv'\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220926_DOY269_extracted_filled'\n",
    "# out_path = 'output/'\n",
    "\n",
    "# name_tag = img_path[-23:-17]\n",
    "# # print(name_tag)\n",
    "\n",
    "# key_word_list = ['Ref_filled.tif', 'RGB_filled.tif']\n",
    "# suffix_list_list = [None, ['LWIR_filled.tif']]\n",
    "\n",
    "# # suffix = ['base', 'lwir']\n",
    "# # suffix_list = ['LWIR_filled.tif']\n",
    "# VI_list = []\n",
    "\n",
    "# selection = 'Pioneer' # \n",
    "# # selection = 'Pioneer Deficit' \n",
    "# # selection = 'Pioneer Full'\n",
    "# pioneer_img_list, pioneer_yield_list, pioneer_type_list = select_data_and_yield_list(\n",
    "# img_path, yield_file, key_word = 'Ref_filled.tif', selection = selection)\n",
    "\n",
    "# print(pioneer_img_list[0])\n",
    "# print(pioneer_img_list[100])\n",
    "# print(pioneer_img_list[1000])\n",
    "# print(pioneer_img_list[2000])\n",
    "# print(pioneer_img_list[3000])\n",
    "\n",
    "# pioneer_dataset = get_ml_image(pioneer_img_list, VI_list=VI_list, suffix_list = [])\n",
    "# pioneer_yield = np.array(pioneer_yield_list)\n",
    "# pioneer_type = np.array(pioneer_type_list)\n",
    "# index_pivot = 1740\n",
    "\n",
    "# # \n",
    "# original_indices = np.arange(len(pioneer_yield))\n",
    "# train_images, test_images, train_yields, test_yields, train_indices, test_indices = train_test_split(\n",
    "# pioneer_dataset, pioneer_yield, original_indices, test_size=0.2, random_state=39)\n",
    "# index_1 = test_yields[np.where(test_indices<index_pivot)]\n",
    "# index_2 = test_yields[np.where(test_indices>=index_pivot)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc920276",
   "metadata": {},
   "source": [
    "Draw plots from result csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from path_utils import get_files_by_suffix\n",
    "# from ml.ml_predict import plot_result, plot_result_separate\n",
    "# fig_path = './output/Ref+NDVI'\n",
    "# suffixe = 'csv'\n",
    "# files = get_files_by_suffix(fig_path, suffixe)\n",
    "\n",
    "# for file in files:\n",
    "#     data = np.loadtxt(file)\n",
    "#     savename = file[:-4]\n",
    "    \n",
    "#     # plot_result(data[:,0], data[:,1], savename)\n",
    "    \n",
    "#     plot_result_separate(data[:,0], data[:,1],test_indices, 1740, savename)\n",
    "#     # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84fd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ab74488",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60aa774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [100, 150, 200],\n",
    "#     'max_depth': [None, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "# MEAN = np.nanmean(train_images,(0,2,3))\n",
    "# STD = np.nanstd(train_images, (0,2,3))\n",
    "# train_images = (train_images- MEAN[None,:,None,None])/STD[None,:,None,None] \n",
    "# train_images = train_images.reshape((train_images.shape[0], -1))\n",
    "# rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# # Create GridSearchCV instance with the model, parameter grid, and cross-validation\n",
    "# grid_search = GridSearchCV(estimator=rf_model\n",
    "# , param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# # Perform the grid search on the dataset\n",
    "# grid_search.fit(train_images, train_yields)\n",
    "\n",
    "# # Print the best parameters and corresponding mean squared error\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Best Mean Squared Error:\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e75e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initiaze the hyperparameters for each dictionary\n",
    "# param1 = {}\n",
    "# param1['classifier'] = [LinearRegression()]\n",
    "\n",
    "# param2 = {}\n",
    "# param2['classifier__alpha'] = [0.1, 0.3, 0.5, 1]\n",
    "# param2['classifier'] = [Ridge()]\n",
    "\n",
    "# param3 = {}\n",
    "# param3['classifier__alpha'] = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "# param3['classifier'] = [Lasso()]\n",
    "\n",
    "# param4 = {}\n",
    "# param4['classifier__n_neighbors'] = [2,5,10,25,50]\n",
    "# param4['classifier'] = [KNeighborsRegressor()]\n",
    "\n",
    "# \"\"\"\n",
    "# param5 = {}\n",
    "# param5['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "# param5['classifier__epsilon'] = [0.0,0.2,0.5,1]\n",
    "# param5['classifier'] = [LinearSVR()]\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09240a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = pipe = Pipeline(steps=[(\"scaler\", CustomScaler(MEAN,STD)),\n",
    "#                        (\"flatten\", FlattenTransformer()),\n",
    "#                        (\"classifier\", LinearRegression())])\n",
    "# params = [param1, param2, param3, param4] # param5\n",
    "# params = [param1, param2, param3, param4] # param5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5137f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the grid search model\n",
    "# grid_search = GridSearchCV(pipeline, params, cv=3, scoring='neg_mean_squared_error').fit(train_images,train_yields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best performing model and its corresponding hyperparameters\n",
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = grid_search.best_estimator_\n",
    "# # predict\n",
    "# pred = model.predict(train_images)\n",
    "\n",
    "# # validate mse error\n",
    "# mse = mean_squared_error(train_yields, pred) \n",
    "# rmse = np.sqrt(mse)\n",
    "\n",
    "# print(mse, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = grid_search.best_estimator_\n",
    "# # predict\n",
    "# pred = model.predict(test_images)\n",
    "\n",
    "# # validate mse error\n",
    "# mse = mean_squared_error(test_yields, pred) \n",
    "# rmse = np.sqrt(mse)\n",
    "\n",
    "# print(mse, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_name = 'test'\n",
    "# plot_result(test_yields, pred, save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
