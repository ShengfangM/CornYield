{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b85590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the new directory path\n",
    "parent_directory = 'c:/Zhou/Ma/Projects/CornYield/src'\n",
    "\n",
    "# Change the current directory\n",
    "os.chdir(parent_directory) \n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e415bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338a8fd",
   "metadata": {},
   "source": [
    "1. read yield data and filled img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960958f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import select_data_and_yield_list\n",
    "from dl.dl_prediction import select_imglist_yield\n",
    "from ml.ml_predict import ml_predict_yield, prepare_train_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_constant import crop_var, irrigate_var, CROP_TYPE\n",
    "from plot_utils import plot_distinct_yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld_label.csv'\n",
    "weather_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/CoAgMet ET_VBA_calc_2022.xlsm'\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "# out_path = '../output/DOY201/'\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220926_DOY269_extracted_filled'\n",
    "# out_path = '../output/DOY269/'\n",
    "# doy=269\n",
    "img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220916_DOY259_extracted_filled'\n",
    "out_path = '../output/DOY259/'\n",
    "doy = 259\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220716_DOY197_extracted_filled'\n",
    "# out_path = '../output/DOY197/'\n",
    "# doy = 197\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220708_DOY189_extracted_filled'\n",
    "# out_path = '../output/DOY189/'\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220705_DOY186_extracted_filled'\n",
    "# out_path = '../output/DOY186/'\n",
    "# doy = 186\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220628_DOY179_extracted_filled'\n",
    "# out_path = '../output/DOY179/'\n",
    "# doy=179\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220616_DOY167_extracted_filled'\n",
    "# out_path = '../output/DOY167/'\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220610_DOY161_extracted_filled'\n",
    "# out_path = '../output/DOY161/'\n",
    "if not os.path.exists(out_path):\n",
    "    # If it doesn't exist, create the directory and any missing parent directories\n",
    "    os.makedirs(out_path)\n",
    "    print(f\"Directory '{out_path}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{out_path}' already exists.\")\n",
    "\n",
    "name_tag = img_path[-23:-17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776054ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "suf_name ={'LWIR': 'Thermal'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e449db",
   "metadata": {},
   "source": [
    "1.0. Image only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044aa5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# key_word_list = ['Ref_filled.tif', 'RGB_filled.tif']\n",
    "\n",
    "# key_word_list = ['Ref_filled.tif']\n",
    "# suffix_list_list = [[], ['LWIR_filled.tif']]\n",
    "key_word_list = ['RGB_filled2.tif']\n",
    "suffix_list_list = [[], ['LWIR_filled2.tif']]\n",
    "# suffix_list_list = [[]]\n",
    "# suffix = ['base', 'lwir']\n",
    "# suffix_list = ['LWIR_filled.tif']\n",
    "# VI_list = ['ndvi', 'ndre', 'gndvi', 'evi']\n",
    "# VI_list = ['ndvi',  'evi']\n",
    "# VI_list = ['ndvi',  'evi', 'ndre', 'gndvi']\n",
    "VI_list = []\n",
    "\n",
    "vi_only = False\n",
    "\n",
    "analyze_variety_id=2\n",
    "analyze_irrigation_id=2\n",
    "train_col='TRAIN_75'\n",
    "\n",
    "for keyword in key_word_list:    \n",
    "    \n",
    "    img_list, yield_pf = select_imglist_yield(yield_file, img_path, keyword, \n",
    "                                            analyze_variety_id=analyze_variety_id, analyze_irrigation_id=analyze_irrigation_id)\n",
    "    \n",
    "    \n",
    "    for suffix_list in suffix_list_list:\n",
    "        train_images, test_images, train_yields, test_yields= prepare_train_test_data(img_list, yield_pf,train_col=train_col, \n",
    "                            VI_list=VI_list, suffix_list=suffix_list, vi_only=False)\n",
    "        \n",
    "        \n",
    "        # test_modes = ['LR']\n",
    "        test_modes = ['Lasso', 'LR', 'GB', 'RF', 'XGB']\n",
    "        # test_modes = ['Lasso', 'LR', 'RF']\n",
    "        # test_modes = ['Lasso', 'LR', 'SVR', 'GB']\n",
    "        for modelname in test_modes:\n",
    "            \n",
    "            out_name = name_tag + ' ' + CROP_TYPE[crop_var[analyze_variety_id]] + ' ' \n",
    "            if not vi_only:\n",
    "                out_name = out_name + keyword[:3]\n",
    "            for vi_name in VI_list:\n",
    "                out_name = out_name + '+' + vi_name.upper()\n",
    "            for suf in suffix_list:\n",
    "                out_name = out_name + '+' + suf_name[suf[:suf.rfind('_')]]\n",
    "            out_name = out_name + ' '\n",
    "            \n",
    "            cur_time = time.time()\n",
    "            trained_model = ml_predict_yield(train_images, train_yields, test_images, modelname, out_name, out_path)\n",
    "            \n",
    "            training_time = time.time() - cur_time\n",
    "            print('training time is : ', training_time)\n",
    "            \n",
    "            \n",
    "            cur_time = time.time()\n",
    "            pred_yields = trained_model.predict(test_images)\n",
    "            predict_time = time.time() - cur_time\n",
    "            print('predict time is : ', predict_time)\n",
    "            \n",
    "            test_irrigate_data = np.array(yield_pf[yield_pf[train_col] == 0]['Irrigation_int'])\n",
    "            test_variety_data = np.array(yield_pf[yield_pf[train_col] == 0]['Variety_int'])\n",
    "\n",
    "            title = out_name +'('+ modelname +') '\n",
    "            out_name = out_name + modelname +' '\n",
    "\n",
    "\n",
    "            result_df=pd.DataFrame({\n",
    "                'Truth': np.array(test_yields), \n",
    "                'Prediction':np.array(pred_yields),\n",
    "                'Irrigation_int':test_irrigate_data,\n",
    "                'Vriaty_int':test_variety_data\n",
    "            })\n",
    "            csv_file_path = out_path+out_name + '.csv'\n",
    "            result_df.to_csv(csv_file_path, index=False)\n",
    "            \n",
    "            \n",
    "            test_yields = np.array(test_yields)\n",
    "            pred_yields = np.array(pred_yields)\n",
    "            plot_distinct_yields(np.array(test_yields), np.array(pred_yields), test_irrigate_data, test_variety_data, title, out_path+out_name)\n",
    "                        \n",
    "#           \n",
    "            if analyze_variety_id >2:\n",
    "                for var_id in set(test_variety_data):\n",
    "                    \n",
    "                    subtitle = title + str(var_id)\n",
    "                    sub_test_yields = test_yields[test_variety_data == var_id]\n",
    "                    sub_pred_yields = pred_yields[test_variety_data == var_id]\n",
    "                    sub_test_irrigate_data = test_irrigate_data[test_variety_data == var_id]\n",
    "                    sub_test_variety_data = test_variety_data[test_variety_data == var_id]\n",
    "                    plot_distinct_yields(sub_test_yields, sub_pred_yields, \n",
    "                                            sub_test_irrigate_data, sub_test_variety_data, subtitle, out_path+subtitle)\n",
    "    #a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc9b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e1c1bb7",
   "metadata": {},
   "source": [
    "2. with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a99626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import create_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e785945",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# key_word_list = ['Ref_filled.tif', 'RGB_filled.tif']\n",
    "key_word_list = ['RGB_filled2.tif']\n",
    "suffix_list_list = [[], ['LWIR_filled2.tif']]\n",
    "# suffix_list_list = [[]]\n",
    "\n",
    "# suffix = ['base', 'lwir']\n",
    "# suffix_list = ['LWIR_filled.tif']\n",
    "# VI_list = ['ndvi', 'ndre', 'gndvi', 'evi']\n",
    "# VI_list = ['ndvi']\n",
    "# VI_list = ['ndvi',  'evi', 'ndre', 'gndvi']\n",
    "VI_list = []\n",
    "\n",
    "vi_only = False\n",
    "\n",
    "analyze_variety_id=2\n",
    "analyze_irrigation_id=2\n",
    "train_col='TRAIN_75'\n",
    "is_meta = True\n",
    "\n",
    "for keyword in key_word_list:    \n",
    "    \n",
    "    img_list, yield_pf = select_imglist_yield(yield_file, img_path, keyword, \n",
    "                                            analyze_variety_id=analyze_variety_id, analyze_irrigation_id=2)\n",
    "    \n",
    "    if analyze_variety_id != 3 or analyze_irrigation_id != 2:\n",
    "        if analyze_variety_id != 3 and analyze_irrigation_id != 2:\n",
    "            yield_pf = yield_pf[(yield_pf['Variety_int'] == analyze_variety_id) & (yield_pf['Irrigation_int'] == analyze_irrigation_id)]\n",
    "        elif analyze_variety_id != 3:\n",
    "            yield_pf = yield_pf[yield_pf['Variety_int'] == analyze_variety_id]\n",
    "        elif  analyze_irrigation_id != 2:\n",
    "            yield_pf = yield_pf[ yield_pf['Irrigation_int'] == analyze_irrigation_id]\n",
    "            \n",
    "        indices = yield_pf.index.tolist()\n",
    "        img_list = [img_list[i] for i in indices]\n",
    "        #### yield_pf = yield_pf[yield_pf['Variety_int'] == analyze_variety_id & yield_pf['Irrigation_int'] == analyze_irrigation_id]\n",
    "        yield_pf = yield_pf.reset_index(drop=True)\n",
    "\n",
    "    # yield_list = list(yield_pf['Yield_Bu_Ac'])\n",
    "    yield_list = list(yield_pf['Yield_MT_Ha'])\n",
    "\n",
    "    '''get metadata'''\n",
    "    metadata = create_metadata(yield_pf, weather_file,doy)\n",
    "    \n",
    "    metadata = metadata.values.tolist()\n",
    "    print(len(metadata))\n",
    "    \n",
    "    for suffix_list in suffix_list_list:\n",
    "        train_images, test_images, train_yields, test_yields= prepare_train_test_data(img_list, yield_pf,metadata=metadata,\n",
    "                            train_col=train_col, VI_list=VI_list, suffix_list=suffix_list, vi_only=False)\n",
    "        \n",
    "        \n",
    "        test_modes = ['Lasso', 'LR','XGB','RF', 'GB']\n",
    "        # test_modes = ['XGB']\n",
    "        # test_modes = ['Lasso', 'LR']\n",
    "        # test_modes = ['Lasso', 'LR', 'SVR', 'GB']\n",
    "        for modelname in test_modes:\n",
    "            \n",
    "            out_name = name_tag + ' ' + CROP_TYPE[crop_var[analyze_variety_id]] + ' ' \n",
    "            if not vi_only:\n",
    "                out_name = out_name + keyword[:3]\n",
    "            for vi_name in VI_list:\n",
    "                out_name = out_name + '+' + vi_name.upper()\n",
    "            for suf in suffix_list:\n",
    "                out_name = out_name + '+' + suf[:suf.rfind('_')]\n",
    "            out_name = out_name + ' '\n",
    "            \n",
    "            cur_time = time.time()\n",
    "            \n",
    "            trained_model = ml_predict_yield(train_images, train_yields, test_images, modelname, out_name, out_path, is_meta)\n",
    "            \n",
    "            training_time = time.time() - cur_time\n",
    "            print('training time is : ', training_time)\n",
    "            \n",
    "            \n",
    "            cur_time = time.time()\n",
    "            pred_yields = trained_model.predict(test_images)\n",
    "            predict_time = time.time() - cur_time\n",
    "            print('predict time is : ', predict_time)\n",
    "            \n",
    "            test_irrigate_data = np.array(yield_pf[yield_pf[train_col] == 0]['Irrigation_int'])\n",
    "            test_variety_data = np.array(yield_pf[yield_pf[train_col] == 0]['Variety_int'])\n",
    "\n",
    "            title = out_name + modelname +' '\n",
    "            out_name = out_name + modelname +' '\n",
    "\n",
    "\n",
    "            result_df=pd.DataFrame({\n",
    "                'Truth': np.array(test_yields), \n",
    "                'Prediction':np.array(pred_yields),\n",
    "                'Irrigation_int':test_irrigate_data,\n",
    "                'Vriaty_int':test_variety_data\n",
    "            })\n",
    "            csv_file_path = out_path+out_name + '.csv'\n",
    "            result_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "            test_yields = np.array(test_yields)\n",
    "            pred_yields = np.array(pred_yields)\n",
    "            plot_distinct_yields(test_yields, pred_yields, test_irrigate_data, test_variety_data, title, out_path+out_name)\n",
    "            \n",
    "            \n",
    "            if analyze_variety_id >2:\n",
    "                for var_id in set(test_variety_data):\n",
    "                    \n",
    "                    subtitle = title + str(var_id)\n",
    "                    sub_test_yields = test_yields[test_variety_data == var_id]\n",
    "                    sub_pred_yields = pred_yields[test_variety_data == var_id]\n",
    "                    sub_test_irrigate_data = test_irrigate_data[test_variety_data == var_id]\n",
    "                    sub_test_variety_data = test_variety_data[test_variety_data == var_id]\n",
    "                    plot_distinct_yields(sub_test_yields, sub_pred_yields, \n",
    "                                            sub_test_irrigate_data, sub_test_variety_data, subtitle, out_path+subtitle)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a53c74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad8e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_yields[test_variety_data == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0cae34",
   "metadata": {},
   "source": [
    "3. Generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list=[\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220616_DOY167_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220628_DOY179_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220708_DOY189_extracted_filled',\n",
    "    'D:/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "]\n",
    "doy_list=[167, 179, 189, 201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddcfccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "image_list = [np.random.rand(64, 64, 3) for _ in range(3000)]  # Replace with your actual list of images\n",
    "\n",
    "# Generate random target variable for illustration purposes (replace this with your actual target)\n",
    "target_variable = np.random.rand(3000)\n",
    "\n",
    "# Flatten each image in the list\n",
    "flattened_images = [image.flatten() for image in image_list]\n",
    "\n",
    "# Convert the list of flattened images to a 2D NumPy array\n",
    "X_flattened = np.array(flattened_images)\n",
    "\n",
    "print(X_flattened.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flattened, target_variable, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "# Create and fit a Lasso regression model\n",
    "lasso_model = Lasso(alpha=0.1)  # Adjust the alpha parameter as needed\n",
    "lasso_model.fit(a, train_yields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443acf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_images[0][0]), len(train_images[1][0]))\n",
    "array_1 = train_images[0].reshape((train_images[0].shape[0], -1))\n",
    "array_2 = train_images[1]\n",
    "a = np.concatenate((array_1, np.array(array_2)),axis=1)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model.fit(a, train_yields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9238b22",
   "metadata": {},
   "source": [
    "\n",
    "## NDVI only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f15b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (5, 64, 64)  # Example: 64x64 image\n",
    "num_samples = 1000\n",
    "\n",
    "# Synthetic 2D image data\n",
    "X_images = np.random.rand(num_samples, *image_shape)\n",
    "\n",
    "# Synthetic 1D CSV data\n",
    "X_csv = np.random.rand(num_samples, 10)\n",
    "\n",
    "X_train = [X_images, X_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae147e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# deficit_indices = list(yield_pf[yield_pf[train_col] == 1].index)\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bacf58",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65347a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld.csv'\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220926_DOY269_extracted_filled'\n",
    "# out_path = 'output/'\n",
    "\n",
    "# name_tag = img_path[-23:-17]\n",
    "# # print(name_tag)\n",
    "\n",
    "# selection = 'Pioneer' # \n",
    "# # selection = 'Pioneer Deficit' \n",
    "# # selection = 'Pioneer Full'\n",
    "# key_word_list = ['Ref_filled.tif']\n",
    "# suffix_list_list = [None, ['LWIR_filled.tif']]\n",
    "\n",
    "# # suffix = ['base', 'lwir']\n",
    "# # suffix_list = ['LWIR_filled.tif']\n",
    "# VI_list = ['ndvi']\n",
    "# for keyword in key_word_list: \n",
    "#     pioneer_img_list, pioneer_yield_list = select_data_and_yield_list(img_path, yield_file, key_word = keyword, selection = selection)\n",
    "\n",
    "#     for suffix_list in suffix_list_list:\n",
    "\n",
    "        \n",
    "#         pioneer_dataset = get_ml_image(pioneer_img_list, VI_list = VI_list, suffix_list = suffix_list)\n",
    "#         print(pioneer_dataset.shape\n",
    "#                 )\n",
    "#         pioneer_yield = np.array(pioneer_yield_list)\n",
    "        \n",
    "#         test_modes = ['Lasso', 'LR', 'RF']\n",
    "#         # test_modes = ['Lasso']\n",
    "#         for modelname in test_modes:\n",
    "            \n",
    "#             # out_name = name_tag + ' ' + selection + ' ' + keyword[:-11] + ' NDVI ' \n",
    "#             out_name = name_tag + ' ' + selection + ' NDVI '  \n",
    "#             if suffix_list is not None:\n",
    "#                 for suf in suffix_list:\n",
    "#                     out_name = out_name + suf[:-11]\n",
    "#             out_name = out_name + ' '\n",
    "#             ml_predict_yield(pioneer_dataset, pioneer_yield, modelname, out_name, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ef25a",
   "metadata": {},
   "source": [
    "### load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from ml.ml_predict import test_model\n",
    "\n",
    "import pickle\n",
    "model_name = 'output\\DOY197\\DOY197 Pioneer +NDVI RF.pkl'\n",
    "# Load the model from the .pkl file using pickle\n",
    "with open(model_name, 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "    \n",
    "    \n",
    "vi_only = True    \n",
    "yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld.csv'\n",
    "img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220720_DOY201_extracted_filled'\n",
    "out_path = 'output/LIRF20220720'\n",
    "\n",
    "name_tag = img_path[-23:-17]\n",
    "# print(name_tag)\n",
    "\n",
    "# key_word_list = ['Ref_filled.tif', 'RGB_filled.tif']\n",
    "key_word_list = ['Ref_filled.tif']\n",
    "suffix_list_list = [[], ['LWIR_filled.tif']]\n",
    "\n",
    "# suffix = ['base', 'lwir']\n",
    "# suffix_list = ['LWIR_filled.tif']\n",
    "# VI_list = ['ndvi', 'ndre', 'gndvi', 'evi']\n",
    "VI_list = ['ndvi']\n",
    "\n",
    "\n",
    "selection = ['Pioneer'] # \n",
    "# selection = 'Pioneer Deficit' \n",
    "# selection = 'Pioneer Full'\n",
    "pioneer_img_list, pioneer_yield_list, irrigate_type_list = select_data_and_yield_list(\n",
    "    img_path, yield_file, key_word = 'Ref_filled.tif', crop_type_select=selection)\n",
    "\n",
    "\n",
    "dataset = get_ml_image(pioneer_img_list, VI_list=VI_list, suffix_list = [], is_vi_only=vi_only)\n",
    "\n",
    "# break\n",
    "yield_data = np.array(pioneer_yield_list)\n",
    "irrigate_data = np.array(irrigate_type_list)\n",
    "\n",
    "    \n",
    "original_indices = np.arange(len(yield_data))\n",
    "train_images, test_images, train_yields, test_yields, train_indices, test_indices = train_test_split(\n",
    "dataset, yield_data, original_indices, test_size=0.2, random_state=39)\n",
    "\n",
    "test_model(model, test_images, test_yields, test_indices, irrigate_data, 'output/apply_model_test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_estimator = model.named_steps['classifier']\n",
    "# # Access feature importances\n",
    "# feature_importances = final_estimator.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc3be1",
   "metadata": {},
   "source": [
    "### get \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# yield_file = 'C:/Users/yutzhou/Desktop/Corn_Yield/BL2022_Yld.csv'\n",
    "# img_path = 'C:/Users/yutzhou/Desktop/Corn_Yield/UAV_Data_Extracted_filled/LIRF20220926_DOY269_extracted_filled'\n",
    "# out_path = 'output/'\n",
    "\n",
    "# name_tag = img_path[-23:-17]\n",
    "# # print(name_tag)\n",
    "\n",
    "# key_word_list = ['Ref_filled.tif', 'RGB_filled.tif']\n",
    "# suffix_list_list = [None, ['LWIR_filled.tif']]\n",
    "\n",
    "# # suffix = ['base', 'lwir']\n",
    "# # suffix_list = ['LWIR_filled.tif']\n",
    "# VI_list = []\n",
    "\n",
    "# selection = 'Pioneer' # \n",
    "# # selection = 'Pioneer Deficit' \n",
    "# # selection = 'Pioneer Full'\n",
    "# pioneer_img_list, pioneer_yield_list, pioneer_type_list = select_data_and_yield_list(\n",
    "# img_path, yield_file, key_word = 'Ref_filled.tif', selection = selection)\n",
    "\n",
    "# print(pioneer_img_list[0])\n",
    "# print(pioneer_img_list[100])\n",
    "# print(pioneer_img_list[1000])\n",
    "# print(pioneer_img_list[2000])\n",
    "# print(pioneer_img_list[3000])\n",
    "\n",
    "# pioneer_dataset = get_ml_image(pioneer_img_list, VI_list=VI_list, suffix_list = [])\n",
    "# pioneer_yield = np.array(pioneer_yield_list)\n",
    "# pioneer_type = np.array(pioneer_type_list)\n",
    "# index_pivot = 1740\n",
    "\n",
    "# # \n",
    "# original_indices = np.arange(len(pioneer_yield))\n",
    "# train_images, test_images, train_yields, test_yields, train_indices, test_indices = train_test_split(\n",
    "# pioneer_dataset, pioneer_yield, original_indices, test_size=0.2, random_state=39)\n",
    "# index_1 = test_yields[np.where(test_indices<index_pivot)]\n",
    "# index_2 = test_yields[np.where(test_indices>=index_pivot)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc920276",
   "metadata": {},
   "source": [
    "Draw plots from result csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981a37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from path_utils import get_files_by_suffix\n",
    "# from ml.ml_predict import plot_result, plot_result_separate\n",
    "# fig_path = './output/Ref+NDVI'\n",
    "# suffixe = 'csv'\n",
    "# files = get_files_by_suffix(fig_path, suffixe)\n",
    "\n",
    "# for file in files:\n",
    "#     data = np.loadtxt(file)\n",
    "#     savename = file[:-4]\n",
    "    \n",
    "#     # plot_result(data[:,0], data[:,1], savename)\n",
    "    \n",
    "#     plot_result_separate(data[:,0], data[:,1],test_indices, 1740, savename)\n",
    "#     # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84fd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ab74488",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60aa774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [100, 150, 200],\n",
    "#     'max_depth': [None, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "# MEAN = np.nanmean(train_images,(0,2,3))\n",
    "# STD = np.nanstd(train_images, (0,2,3))\n",
    "# train_images = (train_images- MEAN[None,:,None,None])/STD[None,:,None,None] \n",
    "# train_images = train_images.reshape((train_images.shape[0], -1))\n",
    "# rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# # Create GridSearchCV instance with the model, parameter grid, and cross-validation\n",
    "# grid_search = GridSearchCV(estimator=rf_model\n",
    "# , param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# # Perform the grid search on the dataset\n",
    "# grid_search.fit(train_images, train_yields)\n",
    "\n",
    "# # Print the best parameters and corresponding mean squared error\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Best Mean Squared Error:\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e75e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initiaze the hyperparameters for each dictionary\n",
    "# param1 = {}\n",
    "# param1['classifier'] = [LinearRegression()]\n",
    "\n",
    "# param2 = {}\n",
    "# param2['classifier__alpha'] = [0.1, 0.3, 0.5, 1]\n",
    "# param2['classifier'] = [Ridge()]\n",
    "\n",
    "# param3 = {}\n",
    "# param3['classifier__alpha'] = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "# param3['classifier'] = [Lasso()]\n",
    "\n",
    "# param4 = {}\n",
    "# param4['classifier__n_neighbors'] = [2,5,10,25,50]\n",
    "# param4['classifier'] = [KNeighborsRegressor()]\n",
    "\n",
    "# \"\"\"\n",
    "# param5 = {}\n",
    "# param5['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "# param5['classifier__epsilon'] = [0.0,0.2,0.5,1]\n",
    "# param5['classifier'] = [LinearSVR()]\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09240a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = pipe = Pipeline(steps=[(\"scaler\", CustomScaler(MEAN,STD)),\n",
    "#                        (\"flatten\", FlattenTransformer()),\n",
    "#                        (\"classifier\", LinearRegression())])\n",
    "# params = [param1, param2, param3, param4] # param5\n",
    "# params = [param1, param2, param3, param4] # param5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5137f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the grid search model\n",
    "# grid_search = GridSearchCV(pipeline, params, cv=3, scoring='neg_mean_squared_error').fit(train_images,train_yields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best performing model and its corresponding hyperparameters\n",
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = grid_search.best_estimator_\n",
    "# # predict\n",
    "# pred = model.predict(train_images)\n",
    "\n",
    "# # validate mse error\n",
    "# mse = mean_squared_error(train_yields, pred) \n",
    "# rmse = np.sqrt(mse)\n",
    "\n",
    "# print(mse, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = grid_search.best_estimator_\n",
    "# # predict\n",
    "# pred = model.predict(test_images)\n",
    "\n",
    "# # validate mse error\n",
    "# mse = mean_squared_error(test_yields, pred) \n",
    "# rmse = np.sqrt(mse)\n",
    "\n",
    "# print(mse, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_name = 'test'\n",
    "# plot_result(test_yields, pred, save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
